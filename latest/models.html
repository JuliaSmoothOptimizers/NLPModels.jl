<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Models · NLPModels.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/><link href="assets/style.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="index.html"><img class="logo" src="assets/logo.png" alt="NLPModels.jl logo"/></a><h1>NLPModels.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Home</a></li><li class="current"><a class="toctext" href="models.html">Models</a><ul class="internal"><li><a class="toctext" href="#ADNLPModel-1">ADNLPModel</a></li><li><a class="toctext" href="#MathProgNLPModel-1">MathProgNLPModel</a></li><li><a class="toctext" href="#SimpleNLPModel-1">SimpleNLPModel</a></li><li><a class="toctext" href="#Derived-Models-1">Derived Models</a></li><li><a class="toctext" href="#ADNLSModel-1">ADNLSModel</a></li><li><a class="toctext" href="#FeasibilityResidual-1">FeasibilityResidual</a></li><li><a class="toctext" href="#LLSModel-1">LLSModel</a></li><li><a class="toctext" href="#SimpleNLSModel-1">SimpleNLSModel</a></li></ul></li><li><a class="toctext" href="tools.html">Tools</a></li><li><a class="toctext" href="tutorial.html">Tutorial</a></li><li><a class="toctext" href="api.html">API</a></li><li><a class="toctext" href="reference.html">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="models.html">Models</a></li></ul><a class="edit-page" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/master/docs/src/models.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Models</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Models-1" href="#Models-1">Models</a></h1><p>The following general models are implemented in this package:</p><ul><li><p><a href="#ADNLPModel-1">ADNLPModel</a></p></li><li><p><a href="#MathProgNLPModel-1">MathProgNLPModel</a></p></li><li><p><a href="#SimpleNLPModel-1">SimpleNLPModel</a></p></li><li><p><a href="#Derived-Models-1">Derived Models</a></p><ul><li><p><a href="#SlackModel-1">SlackModel</a></p></li><li><p><a href="#LBFGSModel-1">LBFGSModel</a></p></li><li><p><a href="#LSR1Model-1">LSR1Model</a></p></li></ul></li></ul><p>In addition, the following nonlinear least squares models are implemented in this package:</p><ul><li><p><a href="#ADNLSModel-1">ADNLSModel</a></p></li><li><p><a href="#FeasibilityResidual-1">FeasibilityResidual</a></p></li><li><p><a href="#LLSModel-1">LLSModel</a></p></li><li><p><a href="#SimpleNLSModel-1">SimpleNLSModel</a></p></li></ul><p>There are other external models implemented. In particular,</p><ul><li><p><a href="https://github.com/JuliaSmoothOptimizers/AmplNLReader.jl">AmplModel</a></p></li><li><p><a href="https://github.com/JuliaSmoothOptimizers/CUTEstModel.jl">CUTEstModel</a></p></li></ul><p>There are currently three models implemented in this package, besides the external ones.</p><h2><a class="nav-anchor" id="ADNLPModel-1" href="#ADNLPModel-1">ADNLPModel</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.ADNLPModel" href="#NLPModels.ADNLPModel"><code>NLPModels.ADNLPModel</code></a> — <span class="docstring-category">Type</span>.</div><div><p>ADNLPModel is an AbstractNLPModel using ForwardDiff to compute the derivatives. In this interface, the objective function <span>$f$</span> and an initial estimate are required. If there are constraints, the function <span>$c:\mathbb{R}^n\rightarrow\mathbb{R}^m$</span>  and the vectors <span>$c_L$</span> and <span>$c_U$</span> also need to be passed. Bounds on the variables and an inital estimate to the Lagrangian multipliers can also be provided.</p><pre><code class="language-none">ADNLPModel(f, x0; lvar = [-∞,…,-∞], uvar = [∞,…,∞], y0 = zeros,
  c = NotImplemented, lcon = [-∞,…,-∞], ucon = [∞,…,∞], name = &quot;Generic&quot;)</code></pre><ul><li><p><code>f :: Function</code> - The objective function <span>$f$</span>;</p></li><li><p><code>x0 :: Vector</code> - The initial point of the problem;</p></li><li><p><code>lvar :: Vector</code> - <span>$\ell$</span>, the lower bound of the variables;</p></li><li><p><code>uvar :: Vector</code> - <span>$u$</span>, the upper bound of the variables;</p></li><li><p><code>c :: Function</code> - The constraints function <span>$c$</span>;</p></li><li><p><code>y0 :: Vector</code> - The initial value of the Lagrangian estimates;</p></li><li><p><code>lcon :: Vector</code> - <span>$c_L$</span>, the lower bounds of the constraints function;</p></li><li><p><code>ucon :: Vector</code> - <span>$c_U$</span>, the upper bounds of the constraints function;</p></li><li><p><code>name :: String</code> - A name for the model.</p></li></ul><p>The functions follow the same restrictions of ForwardDiff functions, summarised here:</p><ul><li><p>The function can only be composed of generic Julia functions;</p></li><li><p>The function must accept only one argument;</p></li><li><p>The function&#39;s argument must accept a subtype of Vector;</p></li><li><p>The function should be type-stable.</p></li></ul><p>For contrained problems, the function <span>$c$</span> is required, and it must return an array even when m = 1, and <span>$c_L$</span> and <span>$c_U$</span> should be passed, otherwise the problem is ill-formed. For equality constraints, the corresponding index of <span>$c_L$</span> and <span>$c_U$</span> should be the same.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/autodiff_model.jl#L6-L43">source</a></section><h3><a class="nav-anchor" id="Example-1" href="#Example-1">Example</a></h3><div><pre><code class="language-julia">using NLPModels
f(x) = sum(x.^4)
x = [1.0; 0.5; 0.25; 0.125]
nlp = ADNLPModel(f, x)
grad(nlp, x)</code></pre><pre><code class="language-none">4-element Array{Float64,1}:
 4.0
 0.5
 0.0625
 0.0078125</code></pre></div><h2><a class="nav-anchor" id="MathProgNLPModel-1" href="#MathProgNLPModel-1">MathProgNLPModel</a></h2><pre><code class="language-none">NLPModels.MathProgNLPModel</code></pre><h3><a class="nav-anchor" id="Example-2" href="#Example-2">Example</a></h3><pre><code class="language-">using NLPModels, MathProgBase, JuMP
m = Model()
@variable(m, x[1:4])
@NLobjective(m, Min, sum(x[i]^4 for i=1:4))
nlp = MathProgNLPModel(m)
x0 = [1.0; 0.5; 0.25; 0.125]
grad(nlp, x0)</code></pre><h2><a class="nav-anchor" id="SimpleNLPModel-1" href="#SimpleNLPModel-1">SimpleNLPModel</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.SimpleNLPModel" href="#NLPModels.SimpleNLPModel"><code>NLPModels.SimpleNLPModel</code></a> — <span class="docstring-category">Type</span>.</div><div><p>SimpleNLPModel is an AbstractNLPModel that uses only user-defined functions. In this interface, the objective function <span>$f$</span> and an initial estimate are required. If the user wants to use derivatives, they need to be passed. The same goes for the Hessian and Hessian-Vector product. For constraints, <span>$c:\mathbb{R}^n\rightarrow\mathbb{R}^m$</span>  and the vectors <span>$c_L$</span> and <span>$c_U$</span> also need to be passed. Bounds on the variables and an inital estimate to the Lagrangian multipliers can also be provided. The user can also pass the Jacobian and the Lagrangian Hessian and Hessian-Vector product.</p><pre><code class="language-none">SimpleNLPModel(f, x0; lvar = [-∞,…,-∞], uvar = [∞,…,∞], y0=zeros,
  lcon = [-∞,…,-∞], ucon = [∞,…,∞], name = &quot;Generic&quot;,
  [list of functions])</code></pre><ul><li><p><code>f :: Function</code> - The objective function <span>$f$</span>;</p></li><li><p><code>x0 :: Vector</code> - The initial point of the problem;</p></li><li><p><code>lvar :: Vector</code> - <span>$\ell$</span>, the lower bound of the variables;</p></li><li><p><code>uvar :: Vector</code> - <span>$u$</span>, the upper bound of the variables;</p></li><li><p><code>y0 :: Vector</code> - The initial value of the Lagrangian estimates;</p></li><li><p><code>lcon :: Vector</code> - <span>$c_L$</span>, the lower bounds of the constraints function;</p></li><li><p><code>ucon :: Vector</code> - <span>$c_U$</span>, the upper bounds of the constraints function;</p></li><li><p><code>name :: String</code> - A name for the model.</p></li></ul><p>All functions passed have a direct correlation with a NLP function. You don&#39;t have to define any more than you need, but calling an undefined function will throw a <code>NotImplementedError</code>. The list is</p><ul><li><p><code>g</code> and <code>g!</code>: <span>$\nabla f(x)$</span>, the gradient of the objective function; see <a href="api/#grad">grad</a>.</p><p>gx = g(x) gx = g!(x, gx)</p></li><li><p><code>H</code>: The lower triangle of the Hessian of the objective function or of the Lagrangian; see <a href="api/#hess">hess</a>.</p><p>Hx = H(x; obj_weight=1.0) # if the problem is unconstrained Hx = H(x; obj_weight=1.0, y=zeros) # if the problem is constrained</p></li><li><p><code>Hcoord</code> - The lower triangle of the Hessian of the objective function or of the Lagrangian, in triplet format; see <a href="api/#hess_coord">hess_coord</a>.</p><p>(rows,cols,vals) = Hcoord(x; obj_weight=1.0) # if the problem is unconstrained (rows,cols,vals) = Hcoord(x; obj_weight=1.0, y=zeros) # if the problem is constrained</p></li><li><p><code>Hp</code> and <code>Hp!</code> - The product of the Hessian of the objective function or of the Lagrangian by a vector; see <a href="api/#hprod">hprod</a>.</p><p>Hv = Hp(x, v, obj_weight=1.0) # if the problem is unconstrained Hv = Hp!(x, v, Hv, obj_weight=1.0) # if the problem is unconstrained Hv = Hp(x, v, obj_weight=1.0, y=zeros) # if the problem is constrained Hv = Hp!(x, v, Hv, obj_weight=1.0, y=zeros) # if the problem is constrained</p></li><li><p><code>c</code> and <code>c!</code> - <span>$c(x)$</span>, the constraints function; see <a href="api/#cons">cons</a>.</p><p>cx = c(x) cx = c!(x, cx)</p></li><li><p><code>J</code> - <span>$J(x)$</span>, the Jacobian of the constraints; see <a href="api/#jac">jac</a>.</p><p>Jx = J(x)</p></li><li><p><code>Jcoord</code> - <span>$J(x)$</span>, the Jacobian of the constraints, in triplet format; see <a href="api/#jac_coord">jac_coord</a>.</p><p>(rows,cols,vals) = Jcoord(x)</p></li><li><p><code>Jp</code> and <code>Jp!</code> - The Jacobian-vector product; see <a href="api/#jprod">jprod</a>.</p><p>Jv = Jp(x, v) Jv = Jp!(x, v, Jv)</p></li><li><p><code>Jtp</code> and <code>Jtp!</code> - The Jacobian-transposed-vector product; see <a href="api/#jtprod">jtprod</a>.</p><p>Jtv = Jtp(x, v) Jtv = Jtp!(x, v, Jtv)</p></li></ul><p>For contrained problems, the function <span>$c$</span> is required, and it must return an array even when m = 1, and <span>$c_L$</span> and <span>$c_U$</span> should be passed, otherwise the problem is ill-formed. For equality constraints, the corresponding index of <span>$c_L$</span> and <span>$c_U$</span> should be the same.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/simple_model.jl#L4-L98">source</a></section><h3><a class="nav-anchor" id="Example-3" href="#Example-3">Example</a></h3><div><pre><code class="language-julia">using NLPModels
f(x) = sum(x.^4)
g(x) = 4*x.^3
x = [1.0; 0.5; 0.25; 0.125]
nlp = SimpleNLPModel(f, x, g=g)
grad(nlp, x)</code></pre><pre><code class="language-none">4-element Array{Float64,1}:
 4.0
 0.5
 0.0625
 0.0078125</code></pre></div><h2><a class="nav-anchor" id="Derived-Models-1" href="#Derived-Models-1">Derived Models</a></h2><p>The following models are created from any given model, making some modification to that model.</p><h3><a class="nav-anchor" id="SlackModel-1" href="#SlackModel-1">SlackModel</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.SlackModel" href="#NLPModels.SlackModel"><code>NLPModels.SlackModel</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A model whose only inequality constraints are bounds.</p><p>Given a model, this type represents a second model in which slack variables are introduced so as to convert linear and nonlinear inequality constraints to equality constraints and bounds. More precisely, if the original model has the form</p><p>\[ \min f(x)  \mbox{ s. t. }  c_L \leq c(x) \leq c_U \mbox{ and } \ell \leq x \leq u, \]</p><p>the new model appears to the user as</p><p>\[ \min f(X)  \mbox{ s. t. }  g(X) = 0 \mbox{ and } L \leq X \leq U. \]</p><p>The unknowns <span>$X = (x, s)$</span> contain the original variables and slack variables <span>$s$</span>. The latter are such that the new model has the general form</p><p>\[ \min f(x)  \mbox{ s. t. }  c(x) - s = 0, c_L \leq s \leq c_U \mbox{ and } \ell \leq x \leq u, \]</p><p>although no slack variables are introduced for equality constraints.</p><p>The slack variables are implicitly ordered as [s(low), s(upp), s(rng)], where <code>low</code>, <code>upp</code> and <code>rng</code> represent the indices of the constraints of the form <span>$c_L \leq c(x) &lt; \infty$</span>, <span>$-\infty &lt; c(x) \leq c_U$</span> and <span>$c_L \leq c(x) \leq c_U$</span>, respectively.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/slack_model.jl#L8-L35">source</a></section><h3><a class="nav-anchor" id="Example-4" href="#Example-4">Example</a></h3><div><pre><code class="language-julia">using NLPModels
f(x) = x[1]^2 + 4x[2]^2
c(x) = [x[1]*x[2] - 1]
x = [2.0; 2.0]
nlp = ADNLPModel(f, x, c=c, lcon=[0.0])
nlp_slack = SlackModel(nlp)
nlp_slack.meta.lvar</code></pre><pre><code class="language-none">3-element Array{Float64,1}:
 -Inf
 -Inf
    0.0</code></pre></div><h3><a class="nav-anchor" id="LBFGSModel-1" href="#LBFGSModel-1">LBFGSModel</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.LBFGSModel" href="#NLPModels.LBFGSModel"><code>NLPModels.LBFGSModel</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Construct a <code>LBFGSModel</code> from another type of model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/qn_model.jl#L17">source</a></section><h3><a class="nav-anchor" id="LSR1Model-1" href="#LSR1Model-1">LSR1Model</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.LSR1Model" href="#NLPModels.LSR1Model"><code>NLPModels.LSR1Model</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Construct a <code>LSR1Model</code> from another type of nlp.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/qn_model.jl#L23">source</a></section><h2><a class="nav-anchor" id="ADNLSModel-1" href="#ADNLSModel-1">ADNLSModel</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.ADNLSModel" href="#NLPModels.ADNLSModel"><code>NLPModels.ADNLSModel</code></a> — <span class="docstring-category">Type</span>.</div><div><p>ADNLSModel is an Nonlinear Least Squares model using ForwardDiff to compute the derivatives.</p><pre><code class="language-none">ADNLSModel(F, x0, m; lvar = [-∞,…,-∞], uvar = [∞,…,∞], y0 = zeros,
  c = NotImplemented, lcon = [-∞,…,-∞], ucon = [∞,…,∞], name = &quot;Generic&quot;)</code></pre><ul><li><p><code>F :: Function</code> - The residual function <span>$F$</span>;</p></li><li><p><code>x0 :: Vector</code> - The initial point of the problem;</p></li><li><p><code>m :: Int</code> - The dimension of <span>$F(x)$</span>, i.e., the number of</p></li></ul><p>equations in the nonlinear system.</p><p>The other parameters are as in <code>ADNLPModel</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/autodiff_nlsmodel.jl#L8-L23">source</a></section><div><pre><code class="language-julia">using NLPModels
F(x) = [x[1] - 1; 10*(x[2] - x[1]^2)]
nlp = ADNLSModel(F, [-1.2; 1.0], 2)
residual(nlp, nlp.meta.x0)</code></pre><pre><code class="language-none">2-element Array{Float64,1}:
 -2.2
 -4.4</code></pre></div><h2><a class="nav-anchor" id="FeasibilityResidual-1" href="#FeasibilityResidual-1">FeasibilityResidual</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.FeasibilityResidual" href="#NLPModels.FeasibilityResidual"><code>NLPModels.FeasibilityResidual</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A feasibility residual model is created from a NLPModel of the form</p><pre><code class="language-none">min f(x)
s.t c(x) = 0</code></pre><p>by defining the function F(x) = c(x). If the problem has bounds on the variables or more constraints, an error is thrown.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/feasibility_residual.jl#L4-L13">source</a></section><h2><a class="nav-anchor" id="LLSModel-1" href="#LLSModel-1">LLSModel</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.LLSModel" href="#NLPModels.LLSModel"><code>NLPModels.LLSModel</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">nls = LLSModel(A, b; lvar, uvar, C, lcon, ucon)</code></pre><p>Creates a Linear Least Squares model ½‖Ax - b‖² with optional bounds <code>lvar ≦ x ≦ y</code> and optional linear constraints <code>lcon ≦ Cx ≦ ucon</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/lls_model.jl#L5-L10">source</a></section><h2><a class="nav-anchor" id="SimpleNLSModel-1" href="#SimpleNLSModel-1">SimpleNLSModel</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NLPModels.SimpleNLSModel" href="#NLPModels.SimpleNLSModel"><code>NLPModels.SimpleNLSModel</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">nls = SimpleNLSModel(n;  F=F, F! =F!, JF=JF, JFp=JFp, JFp! =JFp!,
JFtp=JFtp, JFtp! =JFtp!)
nls = SimpleNLSModel(x0; F=F, F! =F!, JF=JF, JFp=JFp, JFp! =JFp!,
JFtp=JFtp, JFtp! =JFtp!)</code></pre><p>Creates a Nonlinear Linear Least Squares model to minimize ‖F(x)‖². If JF = JF(x) is passed, the Jacobian is available.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/27d948f714b9443d161e7afb21fb61e9c9d1cf19/src/simple_nls_model.jl#L6-L14">source</a></section><footer><hr/><a class="previous" href="index.html"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="tools.html"><span class="direction">Next</span><span class="title">Tools</span></a></footer></article></body></html>
