var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"As stated in the Home page, we consider the nonlinear optimization problem in the following format:","category":"page"},{"location":"api/","page":"API","title":"API","text":"beginaligned\nmin quad  f(x) \n c_L leq c(x) leq c_U \n ell leq x leq u\nendaligned","category":"page"},{"location":"api/","page":"API","title":"API","text":"To develop an optimization algorithm, we are usually worried not only with f(x) and c(x), but also with their derivatives. Namely,","category":"page"},{"location":"api/","page":"API","title":"API","text":"nabla f(x), the gradient of f at the point x;\nnabla^2 f(x), the Hessian of f at the point x;\nJ(x) = nabla c(x)^T, the Jacobian of c at the point x;\nnabla^2 f(x) + sum_i=1^m lambda_i nabla^2 c_i(x), the Hessian of the Lagrangian function at the point (xlambda).","category":"page"},{"location":"api/","page":"API","title":"API","text":"There are many ways to access some of these values, so here is a little reference guide.","category":"page"},{"location":"api/#Reference-guide","page":"API","title":"Reference guide","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The following naming should be easy enough to follow. If not, click on the link and go to the description.","category":"page"},{"location":"api/","page":"API","title":"API","text":"! means inplace;\n_coord means coordinate format;\nprod means matrix-vector product;\n_op means operator (as in LinearOperators.jl);\n_lin and _nln respectively refer to linear and nonlinear constraints.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Feel free to open an issue to suggest other methods that should apply to all NLPModels instances.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Function NLPModels function\nf(x) obj, objgrad, objgrad!, objcons, objcons!\nnabla f(x) grad, grad!, objgrad, objgrad!\nnabla^2 f(x) hess, hess_op, hess_op!, hess_coord, hess_coord, hess_structure, hess_structure!, hprod, hprod!\nc(x) cons_lin, cons_lin!, cons_nln, cons_nln!, cons, cons!, objcons, objcons!\nJ(x) jac_lin, jac_nln, jac, jac_lin_op, jac_lin_op!, jac_nln_op, jac_nln_op!,jac_op, jac_op!, jac_lin_coord, jac_lin_coord!, jac_nln_coord, jac_nln_coord!, jac_coord, jac_coord!, jac_lin_structure, jac_lin_structure!, jac_nln_structure, jac_nln_structure!, jac_structure, jprod_lin, jprod_lin!, jprod_nln, jprod_nln!, jprod, jprod!, jtprod_lin, jtprod_lin!, jtprod_nln, jtprod_nln!, jtprod, jtprod!\nnabla^2 L(xy) hess, hess_op, hess_coord, hess_coord!, hess_structure, hess_structure!, hprod, hprod!, jth_hprod, jth_hprod!, jth_hess, jth_hess_coord, jth_hess_coord!, ghjvprod, ghjvprod!","category":"page"},{"location":"api/#nls-api","page":"API","title":"API for NLSModels","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"For the Nonlinear Least Squares models, f(x) = tfrac12 Vert F(x)Vert^2, and these models have additional function to access the residual value and its derivatives. Namely,","category":"page"},{"location":"api/","page":"API","title":"API","text":"J_F(x) = nabla F(x)^T\nnabla^2 F_i(x)","category":"page"},{"location":"api/","page":"API","title":"API","text":"Function function\nF(x) residual, residual!\nJ_F(x) jac_residual, jac_coord_residual, jac_coord_residual!, jac_structure_residual, jac_structure_residual!, jprod_residual, jprod_residual!, jtprod_residual, jtprod_residual!, jac_op_residual, jac_op_residual!\nnabla^2 F_i(x) hess_residual, hess_coord_residual, hess_coord_residual!, hess_structure_residual, hess_structure_residual!, jth_hess_residual, hprod_residual, hprod_residual!, hess_op_residual, hess_op_residual!","category":"page"},{"location":"models/#Models","page":"Models","title":"Models","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"The following is a list of packages implement the NLPModels API.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"If you want your package listed here, open a Pull Request.","category":"page"},{"location":"models/","page":"Models","title":"Models","text":"If you want to create your own interface, check these Guidelines.","category":"page"},{"location":"models/#Packages","page":"Models","title":"Packages","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"NLPModelsModifiers.jl: Models that modify existing models. For instance, creating slack variables, or moving constraints into the objective functions, or using Quasi-Newton LBFSG approximations to the Hessian.\nADNLPModels.jl: Models with automatic differentiation. It has a very simple interface, although it isn't very efficient for larger problems.\nCUTEst.jl: For problems from CUTEst.\nAmplNLReader.jl: For problems modeled using AMPL\nNLPModelsJuMP.jl: For problems modeled using JuMP.jl.\nQuadraticModels.jl: For problems with quadratic and linear structure.\nLLSModels.jl: Creates a linear least squares model.\nPDENLPModels.jl: For PDE-constrained problems.","category":"page"},{"location":"models/#Model-internals","page":"Models","title":"Model internals","text":"","category":"section"},{"location":"models/","page":"Models","title":"Models","text":"AbstractNLPModel\nAbstractNLSModel\nAbstractNLPModelMeta\nNLPModelMeta\nNLSMeta\nnls_meta","category":"page"},{"location":"guidelines/#Guidelines","page":"Guidelines","title":"Guidelines for creating models","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"These are guidelines for the creation of models using NLPModels to help keeping the models uniform, and for future reference in the creation of solvers.","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Table of contents:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Bare minimum\nExpected behaviour\nAdvanced counters\nAdvanced tests","category":"page"},{"location":"guidelines/#bare-minimum","page":"Guidelines","title":"Bare minimum","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Your model should derive from AbstractNLPModel or some other abstract class derived from it. It is mandatory that it have a meta :: NLPModelMeta field, storing all the relevant problem information. The model also needs to provide Counters information. The easiest way is to define counters :: Counters. For instance:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"mutable struct MyModel{T, S} <: AbstractNLPModel{T, S}\n  meta :: NLPModelMeta{T, S}\n  counters :: Counters\nend","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"For alternatives to storing Counters in the model, check advanced counters. The minimum information that should be set for your model through NLPModelMeta is nvar, the number of variables. The following is a valid constructor for MyModel:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"function MyModel()\n  return MyModel(NLPModelMeta(5), Counters())\nend","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"More information can be passed to NLPModelMeta. See the full list here. The essential fields are","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"x0: Starting point (defaults to zeros)\nlvar, uvar: Bounds on the variables (default to (-∞,∞))\nncon: Number of constraints (defaults to 0)\nlcon, ucon: Bounds on the constraints (default to (-∞,∞))\nnnzh: The length of the vectors used to store a triangle of the Hessian in triplet format (defaults to nvar * (nvar + 1) / 2\nnnzj: The length of the vectors used to store the Jacobian in triplet format (default to nvar * ncon)","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"There are about 30 functions in the NLPModels API, and a few with more than one signature. Luckily, many have a default implementation. We collect here the list of functions that should be implemented for a complete API.","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Here, the following notation apply:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"nlp is your instance of MyModel <: AbstractNLPModel\nx is the point where the function is evaluated\ny is the vector of Lagrange multipliers (for constrained problems only)\ng is the gradient vector\nH is the Hessian of the objective or Lagrangian\nhrows, hcols, and hvals are vectors storing the triplet form of the Hessian\nc is the vector of constraints\nJ is the Jacobian of the constraints\njrows, jcols, and jvals are vectors storing the triplet form of the Jacobian\nv is a vector of appropriate dimensions, generally used for operator-vector products\nJv, Jtv, Hv are vectors of appropriate dimensions, storing the result of operator-vector products","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"The following functions should be defined:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Objective (unconstrained models only need to worry about these)\nobj(nlp, x)\ngrad!(nlp, x, g)\nhess_structure!(nlp, hrows, hcols)\nhess_coord!(nlp, x, hvals; obj_weight=1)\nhprod!(nlp, x, v, Hv; obj_weight=1) (actually defaults to calling the constrained case)\nConstraints (constrained models need to worry about these and the ones above)\ncons_lin!(nlp, x, c)\ncons_nln!(nlp, x, c)\njac_lin_structure!(nlp, jrows, jcols)\njac_nln_structure!(nlp, jrows, jcols)\njac_lin_coord!(nlp, x, jvals)\njac_nln_coord!(nlp, x, jvals)\njprod_lin!(nlp, x, v, Jv)\njprod_nln!(nlp, x, v, Jv)\njtprod_lin!(nlp, x, v, Jtv)\njtprod_nln!(nlp, x, v, Jtv)\nhess_coord!(nlp, x, y, hvals; obj_weight=1)\nhprod!(nlp, x, y, v, Hv; obj_weight=1)","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"The linear constraints are specified at the initialization of the NLPModelMeta using the keyword arguement lin. The indices of linear and nonlinear constraints are respectively available in nlp.meta.lin and nlp.meta.nln. If your model uses only linear (resp. nonlinear) constraints, then it suffices to implement the *_lin (resp. *_nln) functions. Alternatively, one could implement only the functions without the suffixes _nln! (e.g., only cons!), but this might run into errors with tools differentiating linear and nonlinear constraints.","category":"page"},{"location":"guidelines/#expected-behaviour","page":"Guidelines","title":"Expected behaviour","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"The following is a non-exhaustive list of expected behaviour for methods.","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"All in place methods should also return the modified vectors.\nVector inputs should have the correct size. If necessary, the user should pass them using views or slices.\nThe triplet format does not assume order nor uniqueness.","category":"page"},{"location":"guidelines/#show","page":"Guidelines","title":"Show","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"To further specialize your model, you can also define show_header and possibly show. The default show_header simply prints the typeof the NLPModel, so it should be specialized with the specific information that you prefer. For instance, SlackModel defines","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"show_header(io :: IO, nlp :: SlackModel) = println(io, \"SlackModel - Model with slack variables\")","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Furthermore, we define a general show that calls show_header and specific show functions for the meta and the counters. If your model does not have counters in the default location, you must define show for them as well. Alternatively, you may desire to change the behaviour of show. Here is an example, again from SlackModel:","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"function show(io :: IO, nlp :: SlackModel)\n  show_header(io, nlp)\n  show(io, nlp.meta)\n  show(io, nlp.model.counters)\nend","category":"page"},{"location":"guidelines/#advanced-counters","page":"Guidelines","title":"Advanced counters","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"If a model does not implement counters, then it needs to define","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"neval_xxx(nlp) - get field xxx of Counters\nreset!(nlp) - resetting all counters\nincrement!(nlp, s) - increment counter s","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"For instance","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"for counter in fieldnames(Counters)\n  @eval begin\n    $counter(nlp :: MyModel) = SOMETHING\n  end\nend\nfunction reset!(nlp :: MyModel)\n  RESET COUNTERS\nend\nfunction increment!(nlp :: MyModel, s :: Symbol)\n  INCREMENT COUNTER s\nend","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"One example of such model is the SlackModel, which stores an internal model :: AbstractNLPModel, thus defining","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"$counter(nlp :: SlackModel) = $counter(nlp.model)\nreset!(nlp :: SlackModel) = reset!(nlp.model)\nincrement!(nlp :: SlackModel, s :: Symbol) = increment!(nlp.model, s)","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"This construction can be replicated calling the macro @default_counters Model inner. In the case of SlackModel, the equivalent call is","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"@default_counters SlackModel model","category":"page"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"Furthermore, the show method has to be updated with the correct direction of counter. See show for more information.","category":"page"},{"location":"guidelines/#advanced-tests","page":"Guidelines","title":"Advanced tests","text":"","category":"section"},{"location":"guidelines/","page":"Guidelines","title":"Guidelines","text":"We have created the package NLPModelsTest.jl which defines test functions and problems. To make sure that your model is robust, we recommend using that package.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [NLPModels]","category":"page"},{"location":"reference/#NLPModels.AbstractNLPModel","page":"Reference","title":"NLPModels.AbstractNLPModel","text":"AbstractNLPModel\n\nBase type for an optimization model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.AbstractNLPModelMeta","page":"Reference","title":"NLPModels.AbstractNLPModelMeta","text":"AbstractNLPModelMeta\n\nBase type for metadata related to an optimization model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.AbstractNLSModel","page":"Reference","title":"NLPModels.AbstractNLSModel","text":"AbstractNLSModel <: AbstractNLPModel\n\nBase type for a nonlinear least-squares model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.Counters","page":"Reference","title":"NLPModels.Counters","text":"Counters\n\nStruct for storing the number of function evaluations.\n\n\n\nCounters()\n\nCreates an empty Counters struct.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.DimensionError","page":"Reference","title":"NLPModels.DimensionError","text":"DimensionError <: Exception\nDimensionError(name, dim_expected, dim_found)\n\nError for unexpected dimension. Output: \"DimensionError: Input name should have length dim_expected not dim_found\"\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLPModelMeta","page":"Reference","title":"NLPModels.NLPModelMeta","text":"NLPModelMeta <: AbstractNLPModelMeta\n\nA composite type that represents the main features of the optimization problem\n\noptimize    obj(x)\nsubject to  lvar ≤    x    ≤ uvar\n            lcon ≤ cons(x) ≤ ucon\n\nwhere x        is an nvar-dimensional vector,       obj      is the real-valued objective function,       cons     is the vector-valued constraint function,       optimize is either \"minimize\" or \"maximize\".\n\nHere, lvar, uvar, lcon and ucon are vectors. Some of their components may be infinite to indicate that the corresponding bound or general constraint is not present.\n\n\n\nNLPModelMeta(nvar; kwargs...)\n\nCreate an NLPModelMeta with nvar variables. The following keyword arguments are accepted:\n\nx0: initial guess\nlvar: vector of lower bounds\nuvar: vector of upper bounds\nnlvb: number of nonlinear variables in both objectives and constraints\nnlvo: number of nonlinear variables in objectives (includes nlvb)\nnlvc: number of nonlinear variables in constraints (includes nlvb)\nncon: number of general constraints\ny0: initial Lagrange multipliers\nlcon: vector of constraint lower bounds\nucon: vector of constraint upper bounds\nnnzo: number of nonzeros in the gradient\nnnzj: number of elements needed to store the nonzeros in the sparse Jacobian\nlin_nnzj: number of elements needed to store the nonzeros in the sparse Jacobian of linear constraints\nnln_nnzj: number of elements needed to store the nonzeros in the sparse Jacobian of nonlinear constraints\nnnzh: number of elements needed to store the nonzeros in the sparse Hessian\nlin: indices of linear constraints\nminimize: true if optimize == minimize\nislp: true if the problem is a linear program\nname: problem name\n\nNLPModelMeta also contains the following attributes:\n\nnvar: number of variables\nifix: indices of fixed variables\nilow: indices of variables with lower bound only\niupp: indices of variables with upper bound only\nirng: indices of variables with lower and upper bound (range)\nifree: indices of free variables\niinf: indices of visibly infeasible bounds\njfix: indices of equality constraints\njlow: indices of constraints of the form c(x) ≥ cl\njupp: indices of constraints of the form c(x) ≤ cu\njrng: indices of constraints of the form cl ≤ c(x) ≤ cu\njfree: indices of \"free\" constraints (there shouldn't be any)\njinf: indices of the visibly infeasible constraints\nnlin: number of linear constraints\nnnln: number of nonlinear general constraints\nnln: indices of nonlinear constraints\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLSCounters","page":"Reference","title":"NLPModels.NLSCounters","text":"NLSCounters\n\nStruct for storing the number of functions evaluations for nonlinear least-squares models. NLSCounters also stores a Counters instance named counters.\n\n\n\nNLSCounters()\n\nCreates an empty NLSCounters struct.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLSMeta","page":"Reference","title":"NLPModels.NLSMeta","text":"NLSMeta\n\nBase type for metadata related to a nonlinear least-squares model.\n\n\n\nNLSMeta(nequ, nvar; kwargs...)\n\nCreate a NLSMeta with nequ equations and nvar variables. The following keyword arguments are accepted:\n\nx0: initial guess\nnnzj: number of elements needed to store the nonzeros of the Jacobian of the residual\nnnzh: number of elements needed to store the nonzeros of the sum of Hessians of the residuals\nlin: indices of linear residuals\n\nNLSMeta also contains the following attributes:\n\nnequ: size of the residual\nnvar: number of variables\nnln: indices of nonlinear residuals\nnnln: number of nonlinear general residuals\nnlin: number of linear residuals\n\n\n\n\n\n","category":"type"},{"location":"reference/#LinearOperators.reset!-Tuple{AbstractNLPModel}","page":"Reference","title":"LinearOperators.reset!","text":"reset!(nlp)\n\nReset evaluation count in nlp\n\n\n\n\n\n","category":"method"},{"location":"reference/#LinearOperators.reset!-Tuple{Counters}","page":"Reference","title":"LinearOperators.reset!","text":"reset!(counters)\n\nReset evaluation counters\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.bound_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.bound_constrained","text":"bound_constrained(nlp)\nbound_constrained(meta)\n\nReturns whether the problem has bounds on the variables and no other constraints.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.cons!","text":"c = cons!(nlp, x, c)\n\nEvaluate c(x), the constraints at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.cons","text":"c = cons(nlp, x)\n\nEvaluate c(x), the constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons_lin!","page":"Reference","title":"NLPModels.cons_lin!","text":"c = cons_lin!(nlp, x, c)\n\nEvaluate the linear constraints at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.cons_lin-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.cons_lin","text":"c = cons_lin(nlp, x)\n\nEvaluate the linear constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons_nln!","page":"Reference","title":"NLPModels.cons_nln!","text":"c = cons_nln!(nlp, x, c)\n\nEvaluate the nonlinear constraints at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.cons_nln-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.cons_nln","text":"c = cons_nln(nlp, x)\n\nEvaluate the nonlinear constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.coo_prod!-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.coo_prod!","text":"coo_prod!(rows, cols, vals, v, Av)\n\nCompute the product of a matrix A given by (rows, cols, vals) and the vector v. The result is stored in Av, which should have length equals to the number of rows of A.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.coo_sym_prod!-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.coo_sym_prod!","text":"coo_sym_prod!(rows, cols, vals, v, Av)\n\nCompute the product of a symmetric matrix A given by (rows, cols, vals) and the vector v. The result is stored in Av, which should have length equals to the number of rows of A. Only one triangle of A should be passed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.decrement!-Tuple{AbstractNLPModel, Symbol}","page":"Reference","title":"NLPModels.decrement!","text":"decrement!(nlp, s)\n\nDecrement counter s of problem nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.equality_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.equality_constrained","text":"equality_constrained(nlp)\nequality_constrained(meta)\n\nReturns whether the problem's constraints are all equalities. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ifix-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ifix","text":"get_ifix(nlp)\nget_ifix(meta)\n\nReturn the value ifix from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ifree-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ifree","text":"get_ifree(nlp)\nget_ifree(meta)\n\nReturn the value ifree from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_iinf-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_iinf","text":"get_iinf(nlp)\nget_iinf(meta)\n\nReturn the value iinf from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ilow-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ilow","text":"get_ilow(nlp)\nget_ilow(meta)\n\nReturn the value ilow from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_irng-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_irng","text":"get_irng(nlp)\nget_irng(meta)\n\nReturn the value irng from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_islp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_islp","text":"get_islp(nlp)\nget_islp(meta)\n\nReturn the value islp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_iupp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_iupp","text":"get_iupp(nlp)\nget_iupp(meta)\n\nReturn the value iupp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jfix-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jfix","text":"get_jfix(nlp)\nget_jfix(meta)\n\nReturn the value jfix from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jfree-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jfree","text":"get_jfree(nlp)\nget_jfree(meta)\n\nReturn the value jfree from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jinf-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jinf","text":"get_jinf(nlp)\nget_jinf(meta)\n\nReturn the value jinf from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jlow-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jlow","text":"get_jlow(nlp)\nget_jlow(meta)\n\nReturn the value jlow from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jrng-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jrng","text":"get_jrng(nlp)\nget_jrng(meta)\n\nReturn the value jrng from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jupp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jupp","text":"get_jupp(nlp)\nget_jupp(meta)\n\nReturn the value jupp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lcon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lcon","text":"get_lcon(nlp)\nget_lcon(meta)\n\nReturn the value lcon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lin","text":"get_lin(nlp)\nget_lin(meta)\n\nReturn the value lin from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_lin","text":"get_lin(nls)\nget_lin(nls_meta)\n\nReturn the value lin from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lin_nnzj","text":"get_lin_nnzj(nlp)\nget_lin_nnzj(meta)\n\nReturn the value lin_nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lvar","text":"get_lvar(nlp)\nget_lvar(meta)\n\nReturn the value lvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_minimize-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_minimize","text":"get_minimize(nlp)\nget_minimize(meta)\n\nReturn the value minimize from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_name-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_name","text":"get_name(nlp)\nget_name(meta)\n\nReturn the value name from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ncon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ncon","text":"get_ncon(nlp)\nget_ncon(meta)\n\nReturn the value ncon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nequ-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nequ","text":"get_nequ(nls)\nget_nequ(nls_meta)\n\nReturn the value nequ from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlin-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlin","text":"get_nlin(nlp)\nget_nlin(meta)\n\nReturn the value nlin from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlin-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nlin","text":"get_nlin(nls)\nget_nlin(nls_meta)\n\nReturn the value nlin from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nln","text":"get_nln(nlp)\nget_nln(meta)\n\nReturn the value nln from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nln","text":"get_nln(nls)\nget_nln(nls_meta)\n\nReturn the value nln from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nln_nnzj","text":"get_nln_nnzj(nlp)\nget_nln_nnzj(meta)\n\nReturn the value nln_nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvb-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvb","text":"get_nlvb(nlp)\nget_nlvb(meta)\n\nReturn the value nlvb from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvc-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvc","text":"get_nlvc(nlp)\nget_nlvc(meta)\n\nReturn the value nlvc from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvo-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvo","text":"get_nlvo(nlp)\nget_nlvo(meta)\n\nReturn the value nlvo from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnln-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnln","text":"get_nnln(nlp)\nget_nnln(meta)\n\nReturn the value nnln from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnln-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnln","text":"get_nnln(nls)\nget_nnln(nls_meta)\n\nReturn the value nnln from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzh-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzh","text":"get_nnzh(nlp)\nget_nnzh(meta)\n\nReturn the value nnzh from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzh-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnzh","text":"get_nnzh(nls)\nget_nnzh(nls_meta)\n\nReturn the value nnzh from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzj","text":"get_nnzj(nlp)\nget_nnzj(meta)\n\nReturn the value nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzj-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnzj","text":"get_nnzj(nls)\nget_nnzj(nls_meta)\n\nReturn the value nnzj from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzo-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzo","text":"get_nnzo(nlp)\nget_nnzo(meta)\n\nReturn the value nnzo from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nvar","text":"get_nvar(nlp)\nget_nvar(meta)\n\nReturn the value nvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nvar-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nvar","text":"get_nvar(nls)\nget_nvar(nls_meta)\n\nReturn the value nvar from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ucon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ucon","text":"get_ucon(nlp)\nget_ucon(meta)\n\nReturn the value ucon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_uvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_uvar","text":"get_uvar(nlp)\nget_uvar(meta)\n\nReturn the value uvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_x0-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_x0","text":"get_x0(nlp)\nget_x0(meta)\n\nReturn the value x0 from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_x0-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_x0","text":"get_x0(nls)\nget_x0(nls_meta)\n\nReturn the value x0 from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_y0-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_y0","text":"get_y0(nlp)\nget_y0(meta)\n\nReturn the value y0 from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.ghjvprod!","page":"Reference","title":"NLPModels.ghjvprod!","text":"ghjvprod!(nlp, x, g, v, gHv)\n\nReturn the vector whose i-th component is gᵀ ∇²cᵢ(x) v in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.ghjvprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.ghjvprod","text":"gHv = ghjvprod(nlp, x, g, v)\n\nReturn the vector whose i-th component is gᵀ ∇²cᵢ(x) v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad!","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate f(x), the gradient of the objective function at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.grad!-Tuple{AbstractNLSModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nls, x, g)\ng = grad!(nls, x, g, Fx; recompute::Bool=true)\n\nEvaluate ∇f(x), the gradient of the objective function of nls::AbstractNLSModel at x in place. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.grad","text":"g = grad(nlp, x)\n\nEvaluate f(x), the gradient of the objective function at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_bounds-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_bounds","text":"has_bounds(nlp)\nhas_bounds(meta)\n\nReturns whether the problem has bounds on the variables.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_equalities-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_equalities","text":"has_equalities(nlp)\n\nReturns whether the problem has constraints and at least one of them is an equality. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_inequalities-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_inequalities","text":"has_inequalities(nlp)\n\nReturns whether the problem has constraints and at least one of them is an inequality. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess","text":"Hx = hess(nlp, x, y; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) as a sparse matrix, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . A Symmetric object wrapping the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.hess","text":"Hx = hess(nlp, x; obj_weight=1.0)\n\nEvaluate the objective Hessian at x as a sparse matrix, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight . A Symmetric object wrapping the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord!","page":"Reference","title":"NLPModels.hess_coord!","text":"vals = hess_coord!(nlp, x, y, vals; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight , overwriting vals. Only the lower triangle is returned.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_coord!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_coord!","text":"vals = hess_coord!(nlp, x, vals; obj_weight=1.0)\n\nEvaluate the objective Hessian at x in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight , overwriting vals. Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_coord","text":"vals = hess_coord(nlp, x, y; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.hess_coord","text":"vals = hess_coord(nlp, x; obj_weight=1.0)\n\nEvaluate the objective Hessian at x in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight . Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord_residual!","page":"Reference","title":"NLPModels.hess_coord_residual!","text":"vals = hess_coord_residual!(nls, x, v, vals)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v in sparse coordinate format, rewriting vals.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_coord_residual-Tuple{AbstractNLSModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_coord_residual","text":"vals = hess_coord_residual(nls, x, v)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, x, y, Hv; obj_weight=1.0)\n\nReturn the Lagrangian Hessian at (x,y) with objective function scaled by obj_weight as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v. The vector Hv is used as preallocated storage for the operation.  The linear operator H represents\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, x, Hv; obj_weight=1.0)\n\nReturn the objective Hessian at x with objective function scaled by obj_weight as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v. The vector Hv is used as preallocated storage for the operation.  The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, rows, cols, vals, Hv)\n\nReturn the Hessian given by (rows, cols, vals) as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v.   The vector Hv is used as preallocated storage for the operation.  The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op","text":"H = hess_op(nlp, x, y; obj_weight=1.0)\n\nReturn the Lagrangian Hessian at (x,y) with objective function scaled by obj_weight as a linear operator. The resulting object may be used as if it were a matrix, e.g., H * v. The linear operator H represents\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.hess_op","text":"H = hess_op(nlp, x; obj_weight=1.0)\n\nReturn the objective Hessian at x with objective function scaled by obj_weight as a linear operator. The resulting object may be used as if it were a matrix, e.g., H * v. The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op_residual!-Tuple{AbstractNLSModel, AbstractVector, Int64, AbstractVector}","page":"Reference","title":"NLPModels.hess_op_residual!","text":"Hop = hess_op_residual!(nls, x, i, Hiv)\n\nComputes the Hessian of the i-th residual at x, in linear operator form. The vector Hiv is used as preallocated storage for the operation.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}, Int64}} where {T, S}","page":"Reference","title":"NLPModels.hess_op_residual","text":"Hop = hess_op_residual(nls, x, i)\n\nComputes the Hessian of the i-th residual at x, in linear operator form.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_residual-Tuple{AbstractNLSModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_residual","text":"H = hess_residual(nls, x, v)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v. A Symmetric object wrapping the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_structure!","page":"Reference","title":"NLPModels.hess_structure!","text":"hess_structure!(nlp, rows, cols)\n\nReturn the structure of the Lagrangian Hessian in sparse coordinate format in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.hess_structure","text":"(rows,cols) = hess_structure(nlp)\n\nReturn the structure of the Lagrangian Hessian in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_structure_residual!","page":"Reference","title":"NLPModels.hess_structure_residual!","text":"hess_structure_residual!(nls, rows, cols)\n\nReturns the structure of the residual Hessian in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_structure_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.hess_structure_residual","text":"(rows,cols) = hess_structure_residual(nls)\n\nReturns the structure of the residual Hessian.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.histline-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.histline","text":"histline(s, v, maxv)\n\nReturn a string of the form\n\n______NAME______: ████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 5\n\nwhere:\n\n______NAME______ is s with padding to the left and length 16.\nAnd the symbols █ and ⋅ fill 20 characters in the proportion of v / maxv to █ and the rest to ⋅.\nThe number 5 is v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, x, y, v, Hv; obj_weight=1.0)\n\nEvaluate the product of the Lagrangian Hessian at (x,y) with the vector v in place, with objective function scaled by obj_weight, where the Lagrangian Hessian is\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, rows, cols, vals, v, Hv)\n\nEvaluate the product of the objective or Lagrangian Hessian given by (rows, cols, vals) in triplet format with the vector v in place. Only one triangle of the Hessian should be given.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, x, v, Hv; obj_weight=1.0)\n\nEvaluate the product of the objective Hessian at x with the vector v in place, with objective function scaled by obj_weight, where the objective Hessian is\n\nσ ²f(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hprod","text":"Hv = hprod(nlp, x, y, v; obj_weight=1.0)\n\nEvaluate the product of the Lagrangian Hessian at (x,y) with the vector v, with objective function scaled by obj_weight, where the Lagrangian Hessian is\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hprod","text":"Hv = hprod(nlp, x, v; obj_weight=1.0)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight, where the objective Hessian is\n\nσ ²f(x)\n\nwith σ = obj_weight .\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod_residual!","page":"Reference","title":"NLPModels.hprod_residual!","text":"Hiv = hprod_residual!(nls, x, i, v, Hiv)\n\nComputes the product of the Hessian of the i-th residual at x, times the vector v, and stores it in vector Hiv.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}, Int64, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod_residual","text":"Hiv = hprod_residual(nls, x, i, v)\n\nComputes the product of the Hessian of the i-th residual at x, times the vector v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.increment!-Tuple{AbstractNLPModel, Symbol}","page":"Reference","title":"NLPModels.increment!","text":"increment!(nlp, s)\n\nIncrement counter s of problem nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.increment!-Tuple{AbstractNLSModel, Symbol}","page":"Reference","title":"NLPModels.increment!","text":"increment!(nls, s)\n\nIncrement counter s of problem nls.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.inequality_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.inequality_constrained","text":"inequality_constrained(nlp)\ninequality_constrained(meta)\n\nReturns whether the problem's constraints are all inequalities. Unconstrained problems return true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac","text":"Jx = jac(nlp, x)\n\nEvaluate J(x), the constraints Jacobian at x as a sparse matrix.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_coord!","text":"vals = jac_coord!(nlp, x, vals)\n\nEvaluate J(x), the constraints Jacobian at x in sparse coordinate format, rewriting vals.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_coord","text":"vals = jac_coord(nlp, x)\n\nEvaluate J(x), the constraints Jacobian at x in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord_residual!","page":"Reference","title":"NLPModels.jac_coord_residual!","text":"vals = jac_coord_residual!(nls, x, vals)\n\nComputes the Jacobian of the residual at x in sparse coordinate format, rewriting vals. rows and cols are not rewritten.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_coord_residual-Tuple{AbstractNLSModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_coord_residual","text":"(rows,cols,vals) = jac_coord_residual(nls, x)\n\nComputes the Jacobian of the residual at x in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_lin","text":"Jx = jac_lin(nlp, x)\n\nEvaluate J(x), the linear constraints Jacobian at x as a sparse matrix.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_coord!","page":"Reference","title":"NLPModels.jac_lin_coord!","text":"vals = jac_lin_coord!(nlp, x, vals)\n\nEvaluate J(x), the linear constraints Jacobian at x in sparse coordinate format, overwriting vals.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_lin_coord-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_lin_coord","text":"vals = jac_lin_coord(nlp, x)\n\nEvaluate J(x), the linear constraints Jacobian at x in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_lin_op!","text":"J = jac_lin_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the linear Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_op!","text":"J = jac_lin_op!(nlp, x, Jv, Jtv)\n\nReturn the linear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_op","text":"J = jac_lin_op(nlp, x)\n\nReturn the linear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_structure!","page":"Reference","title":"NLPModels.jac_lin_structure!","text":"jac_lin_structure!(nlp, rows, cols)\n\nReturn the structure of the linear constraints Jacobian in sparse coordinate format in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_lin_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_lin_structure","text":"(rows,cols) = jac_lin_structure(nlp)\n\nReturn the structure of the linear constraints Jacobian in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_nln","text":"Jx = jac_nln(nlp, x)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x as a sparse matrix.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_coord!","page":"Reference","title":"NLPModels.jac_nln_coord!","text":"vals = jac_nln_coord!(nlp, x, vals)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x in sparse coordinate format, overwriting vals.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_nln_coord-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_nln_coord","text":"vals = jac_nln_coord(nlp, x)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_nln_op!","text":"J = jac_nln_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the nonlinear Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_op!","text":"J = jac_nln_op!(nlp, x, Jv, Jtv)\n\nReturn the nonlinear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_op","text":"J = jac_nln_op(nlp, x)\n\nReturn the nonlinear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_structure!","page":"Reference","title":"NLPModels.jac_nln_structure!","text":"jac_nln_structure!(nlp, rows, cols)\n\nReturn the structure of the nonlinear constraints Jacobian in sparse coordinate format in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_nln_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_nln_structure","text":"(rows,cols) = jac_nln_structure(nlp)\n\nReturn the structure of the nonlinear constraints Jacobian in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_op!","text":"J = jac_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op!","text":"J = jac_op!(nlp, x, Jv, Jtv)\n\nReturn the Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.jac_op","text":"J = jac_op(nlp, x)\n\nReturn the Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual!-Tuple{AbstractNLSModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_op_residual!","text":"Jx = jac_op_residual!(nls, x, Jv, Jtv)\n\nComputes J(x), the Jacobian of the residual at x, in linear operator form. The vectors Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual!-Tuple{AbstractNLSModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_op_residual!","text":"Jx = jac_op_residual!(nls, rows, cols, vals, Jv, Jtv)\n\nComputes J(x), the Jacobian of the residual given by (rows, cols, vals), in linear operator form. The vectors Jv and Jtv are used as preallocated storage for the operations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.jac_op_residual","text":"Jx = jac_op_residual(nls, x)\n\nComputes J(x), the Jacobian of the residual at x, in linear operator form.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_residual-Tuple{AbstractNLSModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_residual","text":"Jx = jac_residual(nls, x)\n\nComputes J(x), the Jacobian of the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure!-Union{Tuple{T}, Tuple{AbstractNLPModel, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"NLPModels.jac_structure!","text":"jac_structure!(nlp, rows, cols)\n\nReturn the structure of the constraints Jacobian in sparse coordinate format in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_structure","text":"(rows,cols) = jac_structure(nlp)\n\nReturn the structure of the constraints Jacobian in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure_residual!","page":"Reference","title":"NLPModels.jac_structure_residual!","text":"(rows,cols) = jac_structure_residual!(nls, rows, cols)\n\nReturns the structure of the constraint's Jacobian in sparse coordinate format in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_structure_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.jac_structure_residual","text":"(rows,cols) = jac_structure_residual(nls)\n\nReturns the structure of the constraint's Jacobian in sparse coordinate format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod!","text":"Jv = jprod!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the Jacobian-vector product at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod!","text":"Jv = jprod!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod","text":"Jv = jprod(nlp, x, v)\n\nEvaluate J(x)v, the Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_lin!","page":"Reference","title":"NLPModels.jprod_lin!","text":"Jv = jprod_lin!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the linear Jacobian-vector product at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_lin!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_lin!","text":"Jv = jprod_lin!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the linear Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_lin-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_lin","text":"Jv = jprod_lin(nlp, x, v)\n\nEvaluate J(x)v, the linear Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_nln!","page":"Reference","title":"NLPModels.jprod_nln!","text":"Jv = jprod_nln!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_nln!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_nln!","text":"Jv = jprod_nln!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_nln-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_nln","text":"Jv = jprod_nln(nlp, x, v)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_residual!","page":"Reference","title":"NLPModels.jprod_residual!","text":"Jv = jprod_residual!(nls, x, v, Jv)\n\nComputes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)v, storing it in Jv.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_residual!-Tuple{AbstractNLSModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_residual!","text":"Jv = jprod_residual!(nls, rows, cols, vals, v, Jv)\n\nComputes the product of the Jacobian of the residual given by (rows, cols, vals) and a vector, i.e.,  J(x)v, storing it in Jv.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jprod_residual","text":"Jv = jprod_residual(nls, x, v)\n\nComputes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess-Tuple{AbstractNLPModel, AbstractVector, Integer}","page":"Reference","title":"NLPModels.jth_hess","text":"Hx = jth_hess(nlp, x, j)\n\nEvaluate the Hessian of j-th constraint at x as a sparse matrix with the same sparsity pattern as the Lagrangian Hessian. A Symmetric object wrapping the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_coord!","page":"Reference","title":"NLPModels.jth_hess_coord!","text":"vals = jth_hess_coord!(nlp, x, j, vals)\n\nEvaluate the Hessian of j-th constraint at x in sparse coordinate format, with vals of length nlp.meta.nnzh, in place. Only the lower triangle is returned.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jth_hess_coord-Tuple{AbstractNLPModel, AbstractVector, Integer}","page":"Reference","title":"NLPModels.jth_hess_coord","text":"vals = jth_hess_coord(nlp, x, j)\n\nEvaluate the Hessian of j-th constraint at x in sparse coordinate format. Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_residual-Tuple{AbstractNLSModel, AbstractVector, Int64}","page":"Reference","title":"NLPModels.jth_hess_residual","text":"Hj = jth_hess_residual(nls, x, j)\n\nComputes the Hessian of the j-th residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hprod!","page":"Reference","title":"NLPModels.jth_hprod!","text":"Hv = jth_hprod!(nlp, x, v, j, Hv)\n\nEvaluate the product of the Hessian of j-th constraint at x with the vector v in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jth_hprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, Integer}","page":"Reference","title":"NLPModels.jth_hprod","text":"Hv = jth_hprod(nlp, x, v, j)\n\nEvaluate the product of the Hessian of j-th constraint at x with the vector v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod!","text":"Jtv = jtprod!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product at x in place. If the problem has linear and nonlinear constraints, this function allocates.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod!","text":"Jtv = jtprod!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod","text":"Jtv = jtprod(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_lin!","page":"Reference","title":"NLPModels.jtprod_lin!","text":"Jtv = jtprod_lin!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_lin!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_lin!","text":"Jtv = jtprod_lin!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_lin-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_lin","text":"Jtv = jtprod_lin(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_nln!","page":"Reference","title":"NLPModels.jtprod_nln!","text":"Jtv = jtprod_nln!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_nln!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_nln!","text":"Jtv = jtprod_nln!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_nln-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_nln","text":"Jtv = jtprod_nln(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_residual!","page":"Reference","title":"NLPModels.jtprod_residual!","text":"Jtv = jtprod_residual!(nls, x, v, Jtv)\n\nComputes the product of the transpose of the Jacobian of the residual at x and a vector, i.e.,  J(x)^Tv, storing it in Jtv.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_residual!-Tuple{AbstractNLSModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_residual!","text":"Jtv = jtprod_residual!(nls, rows, cols, vals, v, Jtv)\n\nComputes the product of the transpose of the Jacobian of the residual given by (rows, cols, vals) and a vector, i.e.,  J(x)^Tv, storing it in Jv.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jtprod_residual","text":"Jtv = jtprod_residual(nls, x, v)\n\nComputes the product of the transpose of the Jacobian of the residual at x and a vector, i.e.,  J(x)^Tv.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.linearly_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.linearly_constrained","text":"linearly_constrained(nlp)\nlinearly_constrained(meta)\n\nReturns whether the problem's constraints are known to be all linear.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_description-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.lines_of_description","text":"lines_of_description(meta)\n\nDescribe meta for the show function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_description-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.lines_of_description","text":"lines_of_description(nls_meta)\n\nDescribe nls_meta for the show function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_hist-Tuple{Any, Any}","page":"Reference","title":"NLPModels.lines_of_hist","text":"lines_of_hist(S, V)\n\nReturn a vector of histline(s, v, maxv)s using pairs of s in S and v in V. maxv is given by the maximum of V.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons","text":"neval_cons(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons_lin","text":"neval_cons_lin(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons_nln","text":"neval_cons_nln(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_grad-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_grad","text":"neval_grad(nlp)\n\nGet the number of grad evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hess-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_hess","text":"neval_hess(nlp)\n\nGet the number of hess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hess_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_hess_residual","text":"nevalhessresidual(nlp)\n\nGet the number of hess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_hprod","text":"neval_hprod(nlp)\n\nGet the number of hprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_hprod_residual","text":"nevalhprodresidual(nlp)\n\nGet the number of hprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac","text":"neval_jac(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac_lin","text":"neval_jac_lin(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac_nln","text":"neval_jac_nln(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jac_residual","text":"nevaljacresidual(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jcon-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jcon","text":"neval_jcon(nlp)\n\nGet the number of jcon evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jgrad-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jgrad","text":"neval_jgrad(nlp)\n\nGet the number of jgrad evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhess-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jhess","text":"neval_jhess(nlp)\n\nGet the number of jhess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhess_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jhess_residual","text":"nevaljhessresidual(nlp)\n\nGet the number of jhess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jhprod","text":"neval_jhprod(nlp)\n\nGet the number of jhprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod","text":"neval_jprod(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod_lin","text":"neval_jprod_lin(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod_nln","text":"neval_jprod_nln(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jprod_residual","text":"nevaljprodresidual(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod","text":"neval_jtprod(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod_lin","text":"neval_jtprod_lin(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod_nln","text":"neval_jtprod_nln(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jtprod_residual","text":"nevaljtprodresidual(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_obj-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_obj","text":"neval_obj(nlp)\n\nGet the number of obj evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_residual","text":"neval_residual(nlp)\n\nGet the number of residual evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.nls_meta-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.nls_meta","text":"nls_meta(nls)\n\nReturns the nls_meta structure of nls. Use this instead of nls.nls_meta to handle models that have internal models.\n\nFor basic models nls_meta(nls) is defined as nls.nls_meta, but composite models might not keep nls_meta themselves, so they might specialize it to something like nls.internal.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.obj-Tuple{AbstractNLSModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nls, x)\nf = obj(nls, x, Fx; recompute::Bool=true)\n\nEvaluate f(x), the objective function of nls::AbstractNLSModel. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objcons!-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.objcons!","text":"f = objcons!(nlp, x, c)\n\nEvaluate f(x) and c(x) at x. c is overwritten with the value of c(x).\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objcons-Tuple{Any, Any}","page":"Reference","title":"NLPModels.objcons","text":"f, c = objcons(nlp, x)\n\nEvaluate f(x) and c(x) at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad!-Tuple{AbstractNLSModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.objgrad!","text":"f, g = objgrad!(nls, x, g)\nf, g = objgrad!(nls, x, g, Fx; recompute::Bool=true)\n\nEvaluate f(x) and ∇f(x) of nls::AbstractNLSModel at x. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad!-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.objgrad!","text":"f, g = objgrad!(nlp, x, g)\n\nEvaluate f(x) and f(x) at x. g is overwritten with the value of f(x).\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad-Tuple{Any, Any}","page":"Reference","title":"NLPModels.objgrad","text":"f, g = objgrad(nlp, x)\n\nEvaluate f(x) and f(x) at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.reset_data!-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.reset_data!","text":"reset_data!(nlp)\n\nReset model data if appropriate. This method should be overloaded if a subtype of AbstractNLPModel contains data that should be reset, such as a quasi-Newton linear operator.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.residual!","page":"Reference","title":"NLPModels.residual!","text":"Fx = residual!(nls, x, Fx)\n\nComputes F(x), the residual at x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.residual","text":"Fx = residual(nls, x)\n\nComputes F(x), the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.show_counters-Tuple{IO, Any, Any}","page":"Reference","title":"NLPModels.show_counters","text":"show_counters(io, counters, fields)\n\nShow the fields of the struct counters.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.show_header-Tuple{IO, AbstractNLPModel}","page":"Reference","title":"NLPModels.show_header","text":"show_header(io, nlp)\n\nShow a header for the specific nlp type. Should be imported and defined for every model implementing the NLPModels API.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sparsityline-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.sparsityline","text":"sparsityline(s, v, maxv)\n\nReturn a string of the form\n\n______NAME______: ( 80.00% sparsity)   5\n\nwhere:\n\n______NAME______ is s with padding to the left and length 16.\nThe sparsity value is given by v / maxv.\nThe number 5 is v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sum_counters-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.sum_counters","text":"sum_counters(nlp)\n\nSum all counters of problem nlp except cons, jac, jprod and jtprod.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sum_counters-Tuple{Counters}","page":"Reference","title":"NLPModels.sum_counters","text":"sum_counters(counters)\n\nSum all counters of counters except cons, jac, jprod and jtprod.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.unconstrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.unconstrained","text":"unconstrained(nlp)\nunconstrained(meta)\n\nReturns whether the problem in unconstrained.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.@default_counters-Tuple{Any, Any}","page":"Reference","title":"NLPModels.@default_counters","text":"@default_counters Model inner\n\nDefine functions relating counters of Model to counters of Model.inner.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@default_nlscounters-Tuple{Any, Any}","page":"Reference","title":"NLPModels.@default_nlscounters","text":"@default_nlscounters Model inner\n\nDefine functions relating NLS counters of Model to NLS counters of Model.inner.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@lencheck-Tuple{Any, Vararg{Any}}","page":"Reference","title":"NLPModels.@lencheck","text":"@lencheck n x y z …\n\nCheck that arrays x, y, z, etc. have a prescribed length n.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@rangecheck-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"NLPModels.@rangecheck","text":"@rangecheck ℓ u i j k …\n\nCheck that values i, j, k, etc. are in the range [ℓ,u].\n\n\n\n\n\n","category":"macro"},{"location":"#Home","page":"Home","title":"NLPModels.jl documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides general guidelines to represent non-linear programming (NLP) problems in Julia and a standardized API to evaluate the functions and their derivatives. The main objective is to be able to rely on that API when designing optimization solvers in Julia.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The general form of the optimization problem is","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nmin quad  f(x) \n c_i(x) = 0 quad i in E \n c_L_i leq c_i(x) leq c_U_i quad i in I \n ell leq x leq u\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where fmathbbR^nrightarrowmathbbR, cmathbbR^nrightarrowmathbbR^m, Ecup I = 12dotsm, Ecap I = emptyset, and c_L_i c_U_i ell_j u_j in mathbbRcuppminfty for i = 1dotsm and j = 1dotsn.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For computational reasons, we write","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nmin quad  f(x) \n c_L leq c(x) leq c_U \n ell leq x leq u\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"defining c_L_i = c_U_i for all i in E. The Lagrangian of this problem is defined as","category":"page"},{"location":"","page":"Home","title":"Home","text":"L(xlambdaz^Lz^Usigma) = sigma f(x) + c(x)^Tlambda  + sum_i=1^n z_i^L(x_i-l_i) + sum_i=1^nz_i^U(u_i-x_i)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where sigma is a scaling parameter included for computational reasons. Notice that, for the Hessian, the variables z^L and z^U are not used.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Optimization problems are represented by an instance/subtype of AbstractNLPModel. Such instances are composed of","category":"page"},{"location":"","page":"Home","title":"Home","text":"an instance of NLPModelMeta, which provides information about the problem, including the number of variables, constraints, bounds on the variables, etc.\nother data specific to the provenance of the problem.","category":"page"},{"location":"#Nonlinear-Least-Squares","page":"Home","title":"Nonlinear Least Squares","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A special type of NLPModels are the NLSModels, i.e., Nonlinear Least Squares models. In these problems, the function f(x) is given by tfrac12Vert F(x)Vert^2, where F is referred as the residual function. The individual value of F, as well as of its derivatives, is also available.","category":"page"},{"location":"#Tools","page":"Home","title":"Tools","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"There are a few tools to use on NLPModels, for instance to query whether the problem is constrained or not, and to get the number of function evaluations. See Tools.","category":"page"},{"location":"#Install","page":"Home","title":"Install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install NLPModels.jl with the following command.","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add NLPModels","category":"page"},{"location":"","page":"Home","title":"Home","text":"This will enable the use of the API and the tools described here, and it allows the creation of a manually written model. Look into Models for more information on that subject, and on a list of packages implementing ready-to-use models.","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the Models, the Tools, or the API.","category":"page"},{"location":"#Attributes","page":"Home","title":"Attributes","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"NLPModelMeta objects have the following attributes (with S <: AbstractVector):","category":"page"},{"location":"","page":"Home","title":"Home","text":"Attribute Type Notes\nnvar Int number of variables\nx0 S initial guess\nlvar S vector of lower bounds\nuvar S vector of upper bounds\nifix Vector{Int} indices of fixed variables\nilow Vector{Int} indices of variables with lower bound only\niupp Vector{Int} indices of variables with upper bound only\nirng Vector{Int} indices of variables with lower and upper bound (range)\nifree Vector{Int} indices of free variables\niinf Vector{Int} indices of visibly infeasible bounds\nncon Int total number of general constraints\nnlin Int number of linear constraints\nnnln Int number of nonlinear general constraints\ny0 S initial Lagrange multipliers\nlcon S vector of constraint lower bounds\nucon S vector of constraint upper bounds\nlin Vector{Int} indices of linear constraints\nnln Vector{Int} indices of nonlinear constraints\njfix Vector{Int} indices of equality constraints\njlow Vector{Int} indices of constraints of the form c(x) ≥ cl\njupp Vector{Int} indices of constraints of the form c(x) ≤ cu\njrng Vector{Int} indices of constraints of the form cl ≤ c(x) ≤ cu\njfree Vector{Int} indices of \"free\" constraints (there shouldn't be any)\njinf Vector{Int} indices of the visibly infeasible constraints\nnnzo Int number of nonzeros in the gradient\nnnzj Int number of nonzeros in the sparse Jacobian\nlin_nnzj Int number of nonzeros in the sparse linear constraints Jacobian\nnln_nnzj Int number of nonzeros in the sparse nonlinear constraints Jacobian\nnnzh Int number of nonzeros in the sparse Hessian\nminimize Bool true if optimize == minimize\nislp Bool true if the problem is a linear program\nname String problem name","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This content is released under the MPL2.0 License.","category":"page"},{"location":"#Bug-reports-and-discussions","page":"Home","title":"Bug reports and discussions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to ask a question not suited for a bug report, feel free to start a discussion here. This forum is for general discussion about this repository and the JuliaSmoothOptimizers, so questions about any of our packages are welcome.","category":"page"},{"location":"#Contents","page":"Home","title":"Contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"internals/#Internal-functions","page":"Internals","title":"Internal functions","text":"","category":"section"},{"location":"internals/","page":"Internals","title":"Internals","text":"These functions may or may not be exported. They are used internally.","category":"page"},{"location":"internals/","page":"Internals","title":"Internals","text":"@default_counters\n@default_nlscounters\n@lencheck\n@rangecheck\ncoo_prod!\ncoo_sym_prod!\ndecrement!\nDimensionError\nNLPModels.histline\nincrement!\nNLPModels.lines_of_description\nNLPModels.lines_of_hist\nNLPModels.show_counters\nshow_header\nNLPModels.sparsityline","category":"page"},{"location":"tools/#tools-section","page":"Tools","title":"Tools","text":"","category":"section"},{"location":"tools/#Functions-evaluations","page":"Tools","title":"Functions evaluations","text":"","category":"section"},{"location":"tools/","page":"Tools","title":"Tools","text":"After calling one the API functions to get a function value, the number of times that function was called is stored inside the NLPModel. For instance","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"using ADNLPModels, LinearAlgebra, NLPModels\nnlp = ADNLPModel(x -> dot(x, x), zeros(2))\nfor i = 1:100\n   obj(nlp, rand(2))\nend\nneval_obj(nlp)","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"Some counters are available for all models, some are specific. In particular, there are additional specific counters for the nonlinear least squares models.","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"Counter Description\nneval_obj Objective\nneval_grad Gradient\nneval_cons Constraints\nneval_cons_lin Linear constraints\nneval_cons_nln Nonlinear constraints\nneval_jcon One constraint - unused\nneval_jgrad Gradient of one constraints - unused\nneval_jac Jacobian\nneval_jac_lin Linear constraints Jacobian\nneval_jac_nln Nonlinear constraints Jacobian\nneval_jprod Product of Jacobian and vector\nneval_jprod_lin Product of linear constraints Jacobian and vector\nneval_jprod_nln Product of nonlinear constraints Jacobian and vector\nneval_jtprod Product of transposed Jacobian and vector\nneval_jtprod_lin Product of transposed linear constraints Jacobian and vector\nneval_jtprod_nln Product of transposed nonlinear constraints Jacobian and vector\nneval_hess Hessian\nneval_hprod Product of Hessian and vector\nneval_jhess Individual Lagrangian Hessian evaluations\nneval_jhprod Product of Hessian of j-th function and vector\nneval_residual Residual function of nonlinear least squares model\nneval_jac_residual Jacobian of the residual\nneval_jprod_residual Product of Jacobian of residual and vector\nneval_jtprod_residual Product of transposed Jacobian of residual and vector\nneval_hess_residual Sum of Hessians of residuals\nneval_jhess_residual Hessian of a residual component\nneval_hprod_residual Product of Hessian of a residual component and vector","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"To get the sum of all counters except cons, jac, jprod and jtprod called for a problem, use sum_counters.","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"using ADNLPModels, LinearAlgebra, NLPModels\nnlp = ADNLPModel(x -> dot(x, x), zeros(2))\nobj(nlp, rand(2))\ngrad(nlp, rand(2))\nsum_counters(nlp)","category":"page"},{"location":"tools/#Querying-problem-type","page":"Tools","title":"Querying problem type","text":"","category":"section"},{"location":"tools/","page":"Tools","title":"Tools","text":"There are some variable for querying the problem type:","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"has_bounds: True when not all variables are free.\nbound_constrained: True for problems with bounded variables and no other constraints.\nequality_constrained: True when problem is constrained only by equalities.\nhas_equalities: True when problem has at least one equality constraint.\ninequality_constrained: True when problem is constrained by inequalities.\nhas_inequalities: True when problem has at least one inequality constraint that isn't a bound.\nlinearly_constrained: True when problem is constrained by equalities or inequalities known to be linear.\nunconstrained: True when problem is not constrained.","category":"page"}]
}
