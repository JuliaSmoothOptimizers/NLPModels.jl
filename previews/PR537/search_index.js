var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"As stated in the Home page, we consider the nonlinear optimization problem in the following format:\n\nbeginaligned\nmin quad  f(x) \n c_L leq c(x) leq c_U \n ell leq x leq u\nendaligned\n\nTo develop an optimization algorithm, we are usually worried not only with f(x) and c(x), but also with their derivatives. Namely,\n\nnabla f(x), the gradient of f at the point x;\nnabla^2 f(x), the Hessian of f at the point x;\nJ(x) = nabla c(x)^T, the Jacobian of c at the point x;\nnabla^2 f(x) + sum_i=1^m y_i nabla^2 c_i(x), the Hessian of the Lagrangian function at the point (xy).\n\nThere are many ways to access some of these values, so here is a little reference guide.","category":"section"},{"location":"api/#Reference-guide","page":"API","title":"Reference guide","text":"The following naming should be easy enough to follow. If not, click on the link and go to the description.\n\n! means inplace;\n_coord means coordinate format;\nprod means matrix-vector product;\n_op means operator (as in LinearOperators.jl);\n_lin and _nln respectively refer to linear and nonlinear constraints.\n\nFeel free to open an issue to suggest other methods that should apply to all NLPModels instances.\n\nFunction NLPModels function\nf(x) obj, objgrad, objgrad!, objcons, objcons!\nnabla f(x) grad, grad!, objgrad, objgrad!\nnabla^2 f(x) hess, hess_op, hess_op!, hess_coord, hess_coord!, hess_dense!, hess_structure, hess_structure!, hprod, hprod!\nc(x) cons_lin, cons_lin!, cons_nln, cons_nln!, cons, cons!, objcons, objcons!\nJ(x) jac_lin, jac_nln, jac, jac_lin_op, jac_lin_op!, jac_nln_op, jac_nln_op!,jac_op, jac_op!, jac_lin_coord, jac_lin_coord!, jac_nln_coord, jac_nln_coord!, jac_coord, jac_coord!, jac_dense!, jac_lin_structure, jac_lin_structure!, jac_nln_structure, jac_nln_structure!, jac_structure, jprod_lin, jprod_lin!, jprod_nln, jprod_nln!, jprod, jprod!, jtprod_lin, jtprod_lin!, jtprod_nln, jtprod_nln!, jtprod, jtprod!\nnabla^2 L(xy) hess, hess_op, hess_coord, hess_coord!, hess_dense!, hess_structure, hess_structure!, hprod, hprod!, jth_hprod, jth_hprod!, jth_hess, jth_hess_coord, jth_hess_coord!, ghjvprod, ghjvprod!\n\nIf only a subset of the functions listed above is implemented, you can indicate which ones are not available when creating the NLPModelMeta, using the keyword arguments grad_available, jac_available, hess_available, jprod_available, jtprod_available, and hprod_available. You can also specify whether the Jacobian of the constraints and the Hessian of the objective or Lagrangian are sparse using the keyword arguments sparse_jacobian and sparse_hessian.","category":"section"},{"location":"api/#nls-api","page":"API","title":"API for NLSModels","text":"For the Nonlinear Least Squares models, f(x) = tfrac12 Vert F(x)Vert^2, and these models have additional function to access the residual value and its derivatives. Namely,\n\nJ_F(x) = nabla F(x)^T\nnabla^2 F_i(x)\n\nFunction function\nF(x) residual, residual!\nJ_F(x) jac_residual, jac_coord_residual, jac_coord_residual!, jac_structure_residual, jac_structure_residual!, jprod_residual, jprod_residual!, jtprod_residual, jtprod_residual!, jac_op_residual, jac_op_residual!\nnabla^2 F_i(x) hess_residual, hess_coord_residual, hess_coord_residual!, hess_structure_residual, hess_structure_residual!, jth_hess_residual, jth_hess_residual_coord, jth_hess_residual_coord!, hprod_residual, hprod_residual!, hess_op_residual, hess_op_residual!\n\nIf only a subset of the functions listed above is implemented, you can indicate which ones are not available when creating the NLSMeta, using the keyword arguments jac_residual_available, hess_residual_available, jprod_residual_available, jtprod_residual_available, and hprod_residual_available.","category":"section"},{"location":"models/#Models","page":"Models","title":"Models","text":"The following is a list of packages implementing the NLPModels API.\n\nIf you want your package listed here, open a Pull Request.\n\nIf you want to create your own interface, check these Guidelines.","category":"section"},{"location":"models/#Packages","page":"Models","title":"Packages","text":"NLPModelsModifiers.jl: Models that modify existing models. For instance, creating slack variables, or moving constraints into the objective functions, or using Quasi-Newton LBFSG approximations to the Hessian.\nADNLPModels.jl: Models with automatic differentiation.\nCUTEst.jl: For problems from CUTEst.\nAmplNLReader.jl: For problems modeled using AMPL\nNLPModelsJuMP.jl: For problems modeled using JuMP.jl.\nQuadraticModels.jl: For problems with linear constraints and a quadratic objective (LCQP).\nLLSModels.jl: Creates a linear least squares model.\nPDENLPModels.jl: For PDE-constrained problems.\nBlockNLPModels.jl: For modeling block structured nonlinear optimization problems.","category":"section"},{"location":"models/#Model-internals","page":"Models","title":"Model internals","text":"AbstractNLPModel\nAbstractNLSModel\nAbstractNLPModelMeta\nNLPModelMeta\nNLSMeta\nnls_meta","category":"section"},{"location":"guidelines/#Guidelines","page":"Guidelines","title":"Guidelines for creating models","text":"These are guidelines for the creation of models using NLPModels to help keeping the models uniform, and for future reference in the creation of solvers.\n\nTable of contents:\n\nBare minimum\nExpected behaviour\nAdvanced counters\nAdvanced tests","category":"section"},{"location":"guidelines/#bare-minimum","page":"Guidelines","title":"Bare minimum","text":"Your model should derive from AbstractNLPModel or some other abstract class derived from it. It is mandatory that it have a meta :: NLPModelMeta field, storing all the relevant problem information. The model also needs to provide Counters information. The easiest way is to define counters :: Counters. For instance:\n\nmutable struct MyModel{T, S} <: AbstractNLPModel{T, S}\n  meta :: NLPModelMeta{T, S}\n  counters :: Counters\nend\n\nFor alternatives to storing Counters in the model, check advanced counters. The minimum information that should be set for your model through NLPModelMeta is nvar, the number of variables. The following is a valid constructor for MyModel:\n\nfunction MyModel()\n  return MyModel(NLPModelMeta(5), Counters())\nend\n\nMore information can be passed to NLPModelMeta. See the full list here. The essential fields are\n\nx0: Starting point (defaults to zeros)\nlvar, uvar: Bounds on the variables (default to (-∞,∞))\nncon: Number of constraints (defaults to 0)\nlcon, ucon: Bounds on the constraints (default to (-∞,∞))\nnnzh: The length of the vectors used to store a triangle of the Hessian in triplet format (defaults to nvar * (nvar + 1) / 2\nnnzj: The length of the vectors used to store the Jacobian in triplet format (default to nvar * ncon)\n\nThere are about 30 functions in the NLPModels API, and a few with more than one signature. Luckily, many have a default implementation. We collect here the list of functions that should be implemented for a complete API.\n\nHere, the following notation applies:\n\nnlp is your instance of MyModel <: AbstractNLPModel\nx is the point where the function is evaluated\ny is the vector of Lagrange multipliers (for constrained problems only)\ng is the gradient vector\nH is the Hessian of the objective or Lagrangian\nhrows, hcols, and hvals are vectors storing the triplet form of the Hessian\nc is the vector of constraints\nJ is the Jacobian of the constraints\njrows, jcols, and jvals are vectors storing the triplet form of the Jacobian\nv is a vector of appropriate dimensions, generally used for operator-vector products\nJv, Jtv, Hv are vectors of appropriate dimensions, storing the result of operator-vector products\n\nThe following functions should be defined:\n\nObjective (unconstrained models only need to worry about these)\nobj(nlp, x)\ngrad!(nlp, x, g)\nhess_structure!(nlp, hrows, hcols) (sparse Hessian)\nhess_coord!(nlp, x, hvals; obj_weight=1) (sparse Hessian)\nhess_dense!(nlp, x, Hx; obj_weight=1) (dense Hessian)\nhprod!(nlp, x, v, Hv; obj_weight=1) (actually defaults to calling the constrained case)\nConstraints (constrained models need to worry about these and the ones above)\ncons_lin!(nlp, x, c)\ncons_nln!(nlp, x, c)\njac_lin_structure!(nlp, jrows, jcols) (sparse Jacobian)\njac_nln_structure!(nlp, jrows, jcols) (sparse Jacobian)\njac_lin_coord!(nlp, x, jvals) (sparse Jacobian)\njac_nln_coord!(nlp, x, jvals) (sparse Jacobian)\njac_dense!(nlp, x, Jx) (dense Jacobian)\njprod_lin!(nlp, x, v, Jv)\njprod_nln!(nlp, x, v, Jv)\njtprod_lin!(nlp, x, v, Jtv)\njtprod_nln!(nlp, x, v, Jtv)\nhess_coord!(nlp, x, y, hvals; obj_weight=1) (sparse Hessian)\nhess_dense!(nlp, x, y, Hx; obj_weight=1) (dense Hessian)\nhprod!(nlp, x, y, v, Hv; obj_weight=1)\n\nThe linear constraints are specified at the initialization of the NLPModelMeta using the keyword arguement lin. The indices of linear and nonlinear constraints are respectively available in nlp.meta.lin and nlp.meta.nln. If your model uses only linear (resp. nonlinear) constraints, then it suffices to implement the *_lin (resp. *_nln) functions. Alternatively, one could implement only the functions without the suffixes _nln! (e.g., only cons!), but this might run into errors with tools differentiating linear and nonlinear constraints.\n\nIf the Jacobian or the Hessian of the Lagrangian is dense, there is no need to implement the corresponding *_structure! and *_coord! methods. Only the corresponding *_dense! methods need to be implemented. This is specified at the initialization of NLPModelMeta through the keyword arguments sparse_jacobian and sparse_hessian.","category":"section"},{"location":"guidelines/#availability-api","page":"Guidelines","title":"Availability of the API","text":"If only a subset of the functions listed above is implemented, you can indicate which ones are not available when creating the NLPModelMeta, using the keyword arguments grad_available, jac_available, hess_available, jprod_available, jtprod_available, and hprod_available.\n\nBy default, grad_available, hess_available, and hprod_available are set to true. For constrained problems (ncon > 0), the fields jac_available, jprod_available, and jtprod_available are also set to true. For unconstrained problems (ncon == 0), they default to false.","category":"section"},{"location":"guidelines/#expected-behaviour","page":"Guidelines","title":"Expected behaviour","text":"The following is a non-exhaustive list of expected behaviour for methods.\n\nAll in place methods should also return the modified vectors.\nVector inputs should have the correct size. If necessary, the user should pass them using views or slices.\nThe triplet format does not assume order nor uniqueness.","category":"section"},{"location":"guidelines/#show","page":"Guidelines","title":"Show","text":"To further specialize your model, you can also define show_header and possibly show. The default show_header simply prints the typeof the NLPModel, so it should be specialized with the specific information that you prefer. For instance, SlackModel defines\n\nshow_header(io :: IO, nlp :: SlackModel) = println(io, \"SlackModel - Model with slack variables\")\n\nFurthermore, we define a general show that calls show_header and specific show functions for the meta and the counters. If your model does not have counters in the default location, you must define show for them as well. Alternatively, you may desire to change the behaviour of show. Here is an example, again from SlackModel:\n\nfunction show(io :: IO, nlp :: SlackModel)\n  show_header(io, nlp)\n  show(io, nlp.meta)\n  show(io, nlp.model.counters)\nend","category":"section"},{"location":"guidelines/#advanced-counters","page":"Guidelines","title":"Advanced counters","text":"If a model does not implement counters, then it needs to define\n\nneval_xxx(nlp) - get field xxx of Counters\nreset!(nlp) - resetting all counters\nincrement!(nlp, s) - increment counter s\n\nFor instance\n\nfor counter in fieldnames(Counters)\n  @eval begin\n    $counter(nlp :: MyModel) = SOMETHING\n  end\nend\nfunction reset!(nlp :: MyModel)\n  RESET COUNTERS\nend\nfunction increment!(nlp :: MyModel, s :: Symbol)\n  INCREMENT COUNTER s\nend\n\nOne example of such model is the SlackModel, which stores an internal model :: AbstractNLPModel, thus defining\n\n$counter(nlp :: SlackModel) = $counter(nlp.model)\nreset!(nlp :: SlackModel) = reset!(nlp.model)\nincrement!(nlp :: SlackModel, s :: Symbol) = increment!(nlp.model, s)\n\nThis construction can be replicated calling the macro @default_counters Model inner. In the case of SlackModel, the equivalent call is\n\n@default_counters SlackModel model\n\nFurthermore, the show method has to be updated with the correct direction of counter. See show for more information.","category":"section"},{"location":"guidelines/#advanced-tests","page":"Guidelines","title":"Advanced tests","text":"We have created the package NLPModelsTest.jl which defines test functions and problems. To make sure that your model is robust, we recommend using it in the test suite of your package.","category":"section"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"​","category":"section"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"​\n\nPages = [\"reference.md\"]\n\n​","category":"section"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"​\n\nPages = [\"reference.md\"]\n\n​","category":"section"},{"location":"reference/#NLPModels.AbstractNLPModel","page":"Reference","title":"NLPModels.AbstractNLPModel","text":"AbstractNLPModel\n\nBase type for an optimization model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.AbstractNLPModelMeta","page":"Reference","title":"NLPModels.AbstractNLPModelMeta","text":"AbstractNLPModelMeta\n\nBase type for metadata related to an optimization model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.AbstractNLSModel","page":"Reference","title":"NLPModels.AbstractNLSModel","text":"AbstractNLSModel <: AbstractNLPModel\n\nBase type for a nonlinear least-squares model.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.Counters","page":"Reference","title":"NLPModels.Counters","text":"Counters\n\nStruct for storing the number of function evaluations.\n\n\n\nCounters()\n\nCreates an empty Counters struct.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.DimensionError","page":"Reference","title":"NLPModels.DimensionError","text":"DimensionError <: Exception\nDimensionError(name, dim_expected, dim_found)\n\nError for unexpected dimension. Output: \"DimensionError: Input name should have length dim_expected not dim_found\"\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLPModelMeta","page":"Reference","title":"NLPModels.NLPModelMeta","text":"NLPModelMeta <: AbstractNLPModelMeta\n\nA composite type that represents the main features of the optimization problem\n\noptimize    obj(x)\nsubject to  lvar ≤    x    ≤ uvar\n            lcon ≤ cons(x) ≤ ucon\n\nwhere x        is an nvar-dimensional vector,       obj      is the real-valued objective function,       cons     is the vector-valued constraint function,       optimize is either \"minimize\" or \"maximize\".\n\nHere, lvar, uvar, lcon and ucon are vectors. Some of their components may be infinite to indicate that the corresponding bound or general constraint is not present.\n\n\n\nNLPModelMeta(nvar::Integer; kwargs...)\nNLPModelMeta(meta::AbstractNLPModelMeta; kwargs...)\n\nCreate an NLPModelMeta with nvar variables. Alternatively, create an NLPModelMeta copy from another AbstractNLPModelMeta. The following keyword arguments are accepted:\n\nx0: initial guess\nlvar: vector of lower bounds\nuvar: vector of upper bounds\nnlvb: number of nonlinear variables in both objectives and constraints\nnlvo: number of nonlinear variables in objectives (includes nlvb)\nnlvc: number of nonlinear variables in constraints (includes nlvb)\nncon: number of general constraints\ny0: initial Lagrange multipliers\nlcon: vector of constraint lower bounds\nucon: vector of constraint upper bounds\nnnzo: number of nonzeros in the gradient\nnnzj: number of elements needed to store the nonzeros in the Jacobian\nlin_nnzj: number of elements needed to store the nonzeros in the Jacobian of linear constraints\nnln_nnzj: number of elements needed to store the nonzeros in the Jacobian of nonlinear constraints\nnnzh: number of elements needed to store the nonzeros in the Hessian of the Lagrangian\nlin: indices of linear constraints\nminimize: true if optimize == minimize\nislp: true if the problem is a linear program\nname: problem name\nsparse_jacobian: indicates whether the Jacobian of the constraints is sparse\nsparse_hessian: indicates whether the Hessian of the Lagrangian is sparse\ngrad_available: indicates whether the gradient of the objective is available\njac_available: indicates whether the Jacobian of the constraints is available\nhess_available: indicates whether the Hessian of the Lagrangian is available\njprod_available: indicates whether the Jacobian-vector product J * v is available\njtprod_available: indicates whether the transpose Jacobian-vector product J' * v is available\nhprod_available: indicates whether the Hessian-vector product of the Lagrangian H * v is available\n\nNLPModelMeta also contains the following attributes, which are computed from the variables above:\n\nnvar: number of variables\nifix: indices of fixed variables\nilow: indices of variables with lower bound only\niupp: indices of variables with upper bound only\nirng: indices of variables with lower and upper bound (range)\nifree: indices of free variables\niinf: indices of visibly infeasible bounds\njfix: indices of equality constraints\njlow: indices of constraints of the form c(x) ≥ cl\njupp: indices of constraints of the form c(x) ≤ cu\njrng: indices of constraints of the form cl ≤ c(x) ≤ cu\njfree: indices of \"free\" constraints (there shouldn't be any)\njinf: indices of the visibly infeasible constraints\nnlin: number of linear constraints\nnnln: number of nonlinear general constraints\nnln: indices of nonlinear constraints\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLSCounters","page":"Reference","title":"NLPModels.NLSCounters","text":"NLSCounters\n\nStruct for storing the number of functions evaluations for nonlinear least-squares models. NLSCounters also stores a Counters instance named counters.\n\n\n\nNLSCounters()\n\nCreates an empty NLSCounters struct.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NLPModels.NLSMeta","page":"Reference","title":"NLPModels.NLSMeta","text":"NLSMeta\n\nBase type for metadata related to a nonlinear least-squares model.\n\n\n\nNLSMeta(nequ, nvar; kwargs...)\n\nCreate a NLSMeta with nequ equations and nvar variables. The following keyword arguments are accepted:\n\nx0: initial guess\nnnzj: number of elements needed to store the nonzeros of the Jacobian of the residual\nnnzh: number of elements needed to store the nonzeros of the sum of Hessians of the residuals\nlin: indices of linear residuals\njac_residual_available: indicates whether the sparse Jacobian of the residuals is available\nhess_residual_available: indicates whether the sum of the sparse Hessians of the residuals is available\njprod_residual_available: indicates whether the Jacobian-vector product for the residuals is available\njtprod_residual_available: indicates whether the transpose Jacobian-vector product for the residuals is available\nhprod_residual_available: indicates whether the Hessian-vector product for each residual is available\n\nNLSMeta also contains the following attributes, which are computed from the variables above:\n\nnequ: size of the residual\nnvar: number of variables\nnln: indices of nonlinear residuals\nnnln: number of nonlinear general residuals\nnlin: number of linear residuals\n\n\n\n\n\n","category":"type"},{"location":"reference/#Base.eltype-Union{Tuple{AbstractNLPModel{T, S}}, Tuple{S}, Tuple{T}} where {T, S}","page":"Reference","title":"Base.eltype","text":"eltype(nlp::AbstractNLPModel{T, S})\n\nElement type of nlp.meta.x0.\n\n\n\n\n\n","category":"method"},{"location":"reference/#LinearOperators.reset!-Tuple{AbstractNLPModel}","page":"Reference","title":"LinearOperators.reset!","text":"reset!(nlp)\n\nReset evaluation count and model data (if appropriate) in nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#LinearOperators.reset!-Tuple{Counters}","page":"Reference","title":"LinearOperators.reset!","text":"reset!(counters)\n\nReset evaluation counters\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.bound_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.bound_constrained","text":"bound_constrained(nlp)\nbound_constrained(meta)\n\nReturns whether the problem has bounds on the variables and no other constraints.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.cons!","text":"c = cons!(nlp, x, c)\n\nEvaluate c(x), the constraints at x in place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.cons","text":"c = cons(nlp, x)\n\nEvaluate c(x), the constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons_lin!","page":"Reference","title":"NLPModels.cons_lin!","text":"c = cons_lin!(nlp, x, c)\n\nEvaluate the linear constraints at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.cons_lin-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.cons_lin","text":"c = cons_lin(nlp, x)\n\nEvaluate the linear constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.cons_nln!","page":"Reference","title":"NLPModels.cons_nln!","text":"c = cons_nln!(nlp, x, c)\n\nEvaluate the nonlinear constraints at x in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.cons_nln-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.cons_nln","text":"c = cons_nln(nlp, x)\n\nEvaluate the nonlinear constraints at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.conscale","page":"Reference","title":"NLPModels.conscale","text":"conscale(model::AbstractNLPModel)\n\nReturn a vector of constraint scaling factors for the model. These are typically used to normalize constraints to have similar magnitudes and improve  convergence behavior in nonlinear solvers.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.coo_prod!-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.coo_prod!","text":"coo_prod!(rows, cols, vals, v, Av)\n\nCompute the product of a matrix A given by (rows, cols, vals) and the vector v. The result is stored in Av, which should have length equals to the number of rows of A.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.coo_sym_prod!-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.coo_sym_prod!","text":"coo_sym_prod!(rows, cols, vals, v, Av)\n\nCompute the product of a symmetric matrix A given by (rows, cols, vals) and the vector v. The result is stored in Av, which should have length equals to the number of rows of A. Only one triangle of A should be passed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.decrement!-Tuple{AbstractNLPModel, Symbol}","page":"Reference","title":"NLPModels.decrement!","text":"decrement!(nlp, s)\n\nDecrement counter s of problem nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.equality_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.equality_constrained","text":"equality_constrained(nlp)\nequality_constrained(meta)\n\nReturns whether the problem's constraints are all equalities. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_grad_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_grad_available","text":"get_grad_available(nlp)\nget_grad_available(meta)\n\nReturn the value grad_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_hess_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_hess_available","text":"get_hess_available(nlp)\nget_hess_available(meta)\n\nReturn the value hess_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_hess_residual_available-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_hess_residual_available","text":"get_hess_residual_available(nls)\nget_hess_residual_available(nls_meta)\n\nReturn the value hessresidualavailable from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_hprod_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_hprod_available","text":"get_hprod_available(nlp)\nget_hprod_available(meta)\n\nReturn the value hprod_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_hprod_residual_available-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_hprod_residual_available","text":"get_hprod_residual_available(nls)\nget_hprod_residual_available(nls_meta)\n\nReturn the value hprodresidualavailable from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ifix-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ifix","text":"get_ifix(nlp)\nget_ifix(meta)\n\nReturn the value ifix from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ifree-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ifree","text":"get_ifree(nlp)\nget_ifree(meta)\n\nReturn the value ifree from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_iinf-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_iinf","text":"get_iinf(nlp)\nget_iinf(meta)\n\nReturn the value iinf from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ilow-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ilow","text":"get_ilow(nlp)\nget_ilow(meta)\n\nReturn the value ilow from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_irng-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_irng","text":"get_irng(nlp)\nget_irng(meta)\n\nReturn the value irng from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_islp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_islp","text":"get_islp(nlp)\nget_islp(meta)\n\nReturn the value islp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_iupp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_iupp","text":"get_iupp(nlp)\nget_iupp(meta)\n\nReturn the value iupp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jac_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jac_available","text":"get_jac_available(nlp)\nget_jac_available(meta)\n\nReturn the value jac_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jac_residual_available-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_jac_residual_available","text":"get_jac_residual_available(nls)\nget_jac_residual_available(nls_meta)\n\nReturn the value jacresidualavailable from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jfix-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jfix","text":"get_jfix(nlp)\nget_jfix(meta)\n\nReturn the value jfix from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jfree-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jfree","text":"get_jfree(nlp)\nget_jfree(meta)\n\nReturn the value jfree from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jinf-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jinf","text":"get_jinf(nlp)\nget_jinf(meta)\n\nReturn the value jinf from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jlow-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jlow","text":"get_jlow(nlp)\nget_jlow(meta)\n\nReturn the value jlow from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jprod_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jprod_available","text":"get_jprod_available(nlp)\nget_jprod_available(meta)\n\nReturn the value jprod_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jprod_residual_available-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_jprod_residual_available","text":"get_jprod_residual_available(nls)\nget_jprod_residual_available(nls_meta)\n\nReturn the value jprodresidualavailable from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jrng-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jrng","text":"get_jrng(nlp)\nget_jrng(meta)\n\nReturn the value jrng from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jtprod_available-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jtprod_available","text":"get_jtprod_available(nlp)\nget_jtprod_available(meta)\n\nReturn the value jtprod_available from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jtprod_residual_available-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_jtprod_residual_available","text":"get_jtprod_residual_available(nls)\nget_jtprod_residual_available(nls_meta)\n\nReturn the value jtprodresidualavailable from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_jupp-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_jupp","text":"get_jupp(nlp)\nget_jupp(meta)\n\nReturn the value jupp from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lcon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lcon","text":"get_lcon(nlp)\nget_lcon(meta)\n\nReturn the value lcon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lin","text":"get_lin(nlp)\nget_lin(meta)\n\nReturn the value lin from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_lin","text":"get_lin(nls)\nget_lin(nls_meta)\n\nReturn the value lin from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lin_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lin_nnzj","text":"get_lin_nnzj(nlp)\nget_lin_nnzj(meta)\n\nReturn the value lin_nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_lvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_lvar","text":"get_lvar(nlp)\nget_lvar(meta)\n\nReturn the value lvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_minimize-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_minimize","text":"get_minimize(nlp)\nget_minimize(meta)\n\nReturn the value minimize from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_name-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_name","text":"get_name(nlp)\nget_name(meta)\n\nReturn the value name from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ncon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ncon","text":"get_ncon(nlp)\nget_ncon(meta)\n\nReturn the value ncon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nequ-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nequ","text":"get_nequ(nls)\nget_nequ(nls_meta)\n\nReturn the value nequ from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlin-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlin","text":"get_nlin(nlp)\nget_nlin(meta)\n\nReturn the value nlin from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlin-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nlin","text":"get_nlin(nls)\nget_nlin(nls_meta)\n\nReturn the value nlin from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nln","text":"get_nln(nlp)\nget_nln(meta)\n\nReturn the value nln from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nln","text":"get_nln(nls)\nget_nln(nls_meta)\n\nReturn the value nln from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nln_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nln_nnzj","text":"get_nln_nnzj(nlp)\nget_nln_nnzj(meta)\n\nReturn the value nln_nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvb-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvb","text":"get_nlvb(nlp)\nget_nlvb(meta)\n\nReturn the value nlvb from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvc-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvc","text":"get_nlvc(nlp)\nget_nlvc(meta)\n\nReturn the value nlvc from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nlvo-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nlvo","text":"get_nlvo(nlp)\nget_nlvo(meta)\n\nReturn the value nlvo from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnln-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnln","text":"get_nnln(nlp)\nget_nnln(meta)\n\nReturn the value nnln from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnln-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnln","text":"get_nnln(nls)\nget_nnln(nls_meta)\n\nReturn the value nnln from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzh-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzh","text":"get_nnzh(nlp)\nget_nnzh(meta)\n\nReturn the value nnzh from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzh-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnzh","text":"get_nnzh(nls)\nget_nnzh(nls_meta)\n\nReturn the value nnzh from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzj-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzj","text":"get_nnzj(nlp)\nget_nnzj(meta)\n\nReturn the value nnzj from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzj-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nnzj","text":"get_nnzj(nls)\nget_nnzj(nls_meta)\n\nReturn the value nnzj from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nnzo-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nnzo","text":"get_nnzo(nlp)\nget_nnzo(meta)\n\nReturn the value nnzo from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_nvar","text":"get_nvar(nlp)\nget_nvar(meta)\n\nReturn the value nvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_nvar-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_nvar","text":"get_nvar(nls)\nget_nvar(nls_meta)\n\nReturn the value nvar from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_sparse_hessian-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_sparse_hessian","text":"get_sparse_hessian(nlp)\nget_sparse_hessian(meta)\n\nReturn the value sparse_hessian from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_sparse_jacobian-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_sparse_jacobian","text":"get_sparse_jacobian(nlp)\nget_sparse_jacobian(meta)\n\nReturn the value sparse_jacobian from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_ucon-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_ucon","text":"get_ucon(nlp)\nget_ucon(meta)\n\nReturn the value ucon from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_uvar-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_uvar","text":"get_uvar(nlp)\nget_uvar(meta)\n\nReturn the value uvar from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_x0-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_x0","text":"get_x0(nlp)\nget_x0(meta)\n\nReturn the value x0 from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_x0-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.get_x0","text":"get_x0(nls)\nget_x0(nls_meta)\n\nReturn the value x0 from nls_meta or nls.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.get_y0-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.get_y0","text":"get_y0(nlp)\nget_y0(meta)\n\nReturn the value y0 from meta or nlp.meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.ghjvprod!","page":"Reference","title":"NLPModels.ghjvprod!","text":"ghjvprod!(nlp, x, g, v, gHv)\n\nReturn the vector whose i-th component is gᵀ ∇²cᵢ(x) v in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.ghjvprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.ghjvprod","text":"gHv = ghjvprod(nlp, x, g, v)\n\nReturn the vector whose i-th component is gᵀ ∇²cᵢ(x) v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad!","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate f(x), the gradient of the objective function at x in place. This function is only available if nlp.meta.grad_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.grad!-Tuple{AbstractNLSModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nls, x, g)\ng = grad!(nls, x, g, Fx; recompute::Bool=true)\n\nEvaluate ∇f(x), the gradient of the objective function of nls::AbstractNLSModel at x in place. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x. This function is only available if nls_meta(nls).jtprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.grad","text":"g = grad(nlp, x)\n\nEvaluate f(x), the gradient of the objective function at x. This function is only available if nlp.meta.grad_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_bounds-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_bounds","text":"has_bounds(nlp)\nhas_bounds(meta)\n\nReturns whether the problem has bounds on the variables.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_equalities-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_equalities","text":"has_equalities(nlp)\n\nReturns whether the problem has constraints and at least one of them is an equality. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.has_inequalities-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.has_inequalities","text":"has_inequalities(nlp)\n\nReturns whether the problem has constraints and at least one of them is an inequality. Unconstrained problems return false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess","text":"Hx = hess(nlp, x, y; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) as a sparse matrix, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . A Symmetric object wrapping the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess","text":"Hx = hess(nlp, x; obj_weight=1.0)\n\nEvaluate the objective Hessian at x as a sparse matrix, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight . A Symmetric object wrapping the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord!","page":"Reference","title":"NLPModels.hess_coord!","text":"vals = hess_coord!(nlp, x, y, vals; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight , overwriting vals. Only the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_coord!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_coord!","text":"vals = hess_coord!(nlp, x, vals; obj_weight=1.0)\n\nEvaluate the objective Hessian at x in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight , overwriting vals. Only the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_coord","text":"vals = hess_coord(nlp, x, y; obj_weight=1.0)\n\nEvaluate the Lagrangian Hessian at (x,y) in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . Only the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_coord","text":"vals = hess_coord(nlp, x; obj_weight=1.0)\n\nEvaluate the objective Hessian at x in sparse coordinate format, with objective function scaled by obj_weight, i.e.,\n\nσ ²f(x)\n\nwith σ = obj_weight . Only the lower triangle is returned. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_coord_residual!","page":"Reference","title":"NLPModels.hess_coord_residual!","text":"vals = hess_coord_residual!(nls, x, v, vals)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v in sparse coordinate format, rewriting vals. This function is only available if nls_meta(nls).hess_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_coord_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_coord_residual","text":"vals = hess_coord_residual(nls, x, v)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v in sparse coordinate format. This function is only available if nls_meta(nls).hess_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_dense!","page":"Reference","title":"NLPModels.hess_dense!","text":"Hx = hess_dense!(nlp, x, Hx; obj_weight=1.0)\nHx = hess_dense!(nlp, x, y, Hx; obj_weight=1.0)\n\nThe first method evaluates H(x), the Hessian of the objective at x in dense format, overwriting Hx. The second method evaluates H(xy), the Hessian of the Lagrangian at (x,y) in dense format, overwriting Hx. Only the lower triangular part of Hx needs to be filled. This function is only available when nlp.meta.hess_available is set to true and nlp.meta.sparse_hessian is set to false.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, x, y, Hv; obj_weight=1.0)\n\nReturn the Lagrangian Hessian at (x,y) with objective function scaled by obj_weight as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v. The vector Hv is used as preallocated storage for the operation.  The linear operator H represents\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, x, Hv; obj_weight=1.0)\n\nReturn the objective Hessian at x with objective function scaled by obj_weight as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v. The vector Hv is used as preallocated storage for the operation.  The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op!","text":"H = hess_op!(nlp, rows, cols, vals, Hv)\n\nReturn the Hessian given by (rows, cols, vals) as a linear operator, and storing the result on Hv. The resulting object may be used as if it were a matrix, e.g., w = H * v. The vector Hv is used as preallocated storage for the operation. The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op","text":"H = hess_op(nlp, x, y; obj_weight=1.0)\n\nReturn the Lagrangian Hessian at (x,y) with objective function scaled by obj_weight as a linear operator. The resulting object may be used as if it were a matrix, e.g., H * v. The linear operator H represents\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op","text":"H = hess_op(nlp, x; obj_weight=1.0)\n\nReturn the objective Hessian at x with objective function scaled by obj_weight as a linear operator. The resulting object may be used as if it were a matrix, e.g., H * v. The linear operator H represents\n\nσ ²f(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op_residual!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hess_op_residual!","text":"Hop = hess_op_residual!(nls, x, i, Hiv)\n\nComputes the Hessian of the i-th residual at x, in linear operator form. The vector Hiv is used as preallocated storage for the operation. This function is only available if nls_meta(nls).hprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_op_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64}} where {T, S}","page":"Reference","title":"NLPModels.hess_op_residual","text":"Hop = hess_op_residual(nls, x, i)\n\nComputes the Hessian of the i-th residual at x, in linear operator form.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_residual-Tuple{AbstractNLSModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hess_residual","text":"H = hess_residual(nls, x, v)\n\nComputes the linear combination of the Hessians of the residuals at x with coefficients v. A Symmetric object wrapping the lower triangle is returned. This function is only available if nls_meta(nls).hess_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_structure!","page":"Reference","title":"NLPModels.hess_structure!","text":"hess_structure!(nlp, rows, cols)\n\nReturn the structure of the Lagrangian Hessian in sparse coordinate format in place. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.hess_structure","text":"(rows,cols) = hess_structure(nlp)\n\nReturn the structure of the Lagrangian Hessian in sparse coordinate format. This function is only available when both nlp.meta.hess_available and nlp.meta.sparse_hessian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hess_structure_residual!","page":"Reference","title":"NLPModels.hess_structure_residual!","text":"hess_structure_residual!(nls, rows, cols)\n\nReturns the structure of the residual Hessian in place. This function is only available if nls_meta(nls).hess_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hess_structure_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.hess_structure_residual","text":"(rows,cols) = hess_structure_residual(nls)\n\nReturns the structure of the residual Hessian. This function is only available if nls_meta(nls).hess_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.histline-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.histline","text":"histline(s, v, maxv)\n\nReturn a string of the form\n\n______NAME______: ████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 5\n\nwhere:\n\n______NAME______ is s with padding to the left and length 16.\nAnd the symbols █ and ⋅ fill 20 characters in the proportion of v / maxv to █ and the rest to ⋅.\nThe number 5 is v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, x, y, v, Hv; obj_weight=1.0)\n\nEvaluate the product of the Lagrangian Hessian at (x,y) with the vector v in place, with objective function scaled by obj_weight, where the Lagrangian Hessian is\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, rows, cols, vals, v, Hv)\n\nEvaluate the product of the objective or Lagrangian Hessian given by (rows, cols, vals) in triplet format with the vector v in place. Only one triangle of the Hessian should be given. This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod!","text":"Hv = hprod!(nlp, x, v, Hv; obj_weight=1.0)\n\nEvaluate the product of the objective Hessian at x with the vector v in place, with objective function scaled by obj_weight, where the objective Hessian is\n\nσ ²f(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod","text":"Hv = hprod(nlp, x, y, v; obj_weight=1.0)\n\nEvaluate the product of the Lagrangian Hessian at (x,y) with the vector v, with objective function scaled by obj_weight, where the Lagrangian Hessian is\n\n²L(xy) = σ ²f(x) + sum_i yᵢ ²cᵢ(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod","text":"Hv = hprod(nlp, x, v; obj_weight=1.0)\n\nEvaluate the product of the objective Hessian at x with the vector v, with objective function scaled by obj_weight, where the objective Hessian is\n\nσ ²f(x)\n\nwith σ = obj_weight . This function is only available if nlp.meta.hprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.hprod_residual!","page":"Reference","title":"NLPModels.hprod_residual!","text":"Hiv = hprod_residual!(nls, x, i, v, Hiv)\n\nComputes the product of the Hessian of the i-th residual at x, times the vector v, and stores it in vector Hiv. This function is only available if nls_meta(nls).hprod_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.hprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.hprod_residual","text":"Hiv = hprod_residual(nls, x, i, v)\n\nComputes the product of the Hessian of the i-th residual at x, times the vector v. This function is only available if nls_meta(nls).hprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.increment!-Tuple{AbstractNLPModel, Symbol}","page":"Reference","title":"NLPModels.increment!","text":"increment!(nlp, s)\n\nIncrement counter s of problem nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.increment!-Tuple{AbstractNLSModel, Symbol}","page":"Reference","title":"NLPModels.increment!","text":"increment!(nls, s)\n\nIncrement counter s of problem nls.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.inequality_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.inequality_constrained","text":"inequality_constrained(nlp)\ninequality_constrained(meta)\n\nReturns whether the problem's constraints are all inequalities. Unconstrained problems return true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac","text":"Jx = jac(nlp, x)\n\nEvaluate J(x), the constraints Jacobian at x as a sparse matrix. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jac_coord!","text":"vals = jac_coord!(nlp, x, vals)\n\nEvaluate J(x), the constraints Jacobian at x in sparse coordinate format, overwriting vals. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_coord","text":"vals = jac_coord(nlp, x)\n\nEvaluate J(x), the constraints Jacobian at x in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_coord_residual!","page":"Reference","title":"NLPModels.jac_coord_residual!","text":"vals = jac_coord_residual!(nls, x, vals)\n\nComputes the Jacobian of the residual at x in sparse coordinate format, rewriting vals. rows and cols are not rewritten. This function is only available if nls_meta(nls).jac_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_coord_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_coord_residual","text":"(rows,cols,vals) = jac_coord_residual(nls, x)\n\nComputes the Jacobian of the residual at x in sparse coordinate format. This function is only available if nls_meta(nls).jac_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_dense!","page":"Reference","title":"NLPModels.jac_dense!","text":"Jx = jac_dense!(nlp, x, Jx)\n\nEvaluate J(x), the constraints Jacobian at x in dense format, overwriting Jx. This function is only available when nlp.meta.jac_available is set to true and nlp.meta.sparse_jacobian is set to false.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_lin-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_lin","text":"Jx = jac_lin(nlp, x)\n\nEvaluate J(x), the linear constraints Jacobian at x as a sparse matrix. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_coord!","page":"Reference","title":"NLPModels.jac_lin_coord!","text":"vals = jac_lin_coord!(nlp, x, vals)\n\nEvaluate J(x), the linear constraints Jacobian at x, overwriting vals. It uses a sparse coordinate format when nlp.meta.sparse_jacobian is set to true. Otherwise, vals is expected to be a dense matrix. This function is only available if nlp.meta.jac_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_lin_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_coord","text":"vals = jac_lin_coord(nlp, x)\n\nEvaluate J(x), the linear constraints Jacobian at x in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_op!","text":"J = jac_lin_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the linear Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_op!","text":"J = jac_lin_op!(nlp, x, Jv, Jtv)\n\nReturn the linear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_lin_op","text":"J = jac_lin_op(nlp, x)\n\nReturn the linear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_lin_structure!","page":"Reference","title":"NLPModels.jac_lin_structure!","text":"jac_lin_structure!(nlp, rows, cols)\n\nReturn the structure of the linear constraints Jacobian in sparse coordinate format in place. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_lin_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_lin_structure","text":"(rows,cols) = jac_lin_structure(nlp)\n\nReturn the structure of the linear constraints Jacobian in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln-Tuple{AbstractNLPModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_nln","text":"Jx = jac_nln(nlp, x)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x as a sparse matrix. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_coord!","page":"Reference","title":"NLPModels.jac_nln_coord!","text":"vals = jac_nln_coord!(nlp, x, vals)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x, overwriting vals. It uses a sparse coordinate format when nlp.meta.sparse_jacobian is set to true. Otherwise, vals is expected to be a dense matrix. This function is only available if nlp.meta.jac_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_nln_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_coord","text":"vals = jac_nln_coord(nlp, x)\n\nEvaluate J(x), the nonlinear constraints Jacobian at x in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_op!","text":"J = jac_nln_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the nonlinear Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_op!","text":"J = jac_nln_op!(nlp, x, Jv, Jtv)\n\nReturn the nonlinear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_nln_op","text":"J = jac_nln_op(nlp, x)\n\nReturn the nonlinear Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_nln_structure!","page":"Reference","title":"NLPModels.jac_nln_structure!","text":"jac_nln_structure!(nlp, rows, cols)\n\nReturn the structure of the nonlinear constraints Jacobian in sparse coordinate format in place. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_nln_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_nln_structure","text":"(rows,cols) = jac_nln_structure(nlp)\n\nReturn the structure of the nonlinear constraints Jacobian in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op!","text":"J = jac_op!(nlp, rows, cols, vals, Jv, Jtv)\n\nReturn the Jacobian given by (rows, cols, vals) as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector{T}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op!","text":"J = jac_op!(nlp, x, Jv, Jtv)\n\nReturn the Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or J' * v. The values Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op","text":"J = jac_op(nlp, x)\n\nReturn the Jacobian at x as a linear operator. The resulting object may be used as if it were a matrix, e.g., J * v or  J' * v. This function is only available if both nlp.meta.jprod_available and nlp.meta.jtprod_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op_residual!","text":"Jx = jac_op_residual!(nls, x, Jv, Jtv)\n\nComputes J(x), the Jacobian of the residual at x, in linear operator form. The vectors Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nls_meta(nls).jprod_residual_available and nls_meta(nls).jtprod_residual_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op_residual!","text":"Jx = jac_op_residual!(nls, rows, cols, vals, Jv, Jtv)\n\nComputes J(x), the Jacobian of the residual given by (rows, cols, vals), in linear operator form. The vectors Jv and Jtv are used as preallocated storage for the operations. This function is only available if both nls_meta(nls).jprod_residual_available and nls_meta(nls).jtprod_residual_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_op_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jac_op_residual","text":"Jx = jac_op_residual(nls, x)\n\nComputes J(x), the Jacobian of the residual at x, in linear operator form. This function is only available if both nls_meta(nls).jprod_residual_available and nls_meta(nls).jtprod_residual_available are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_residual-Tuple{AbstractNLSModel, AbstractVector}","page":"Reference","title":"NLPModels.jac_residual","text":"Jx = jac_residual(nls, x)\n\nComputes J(x), the Jacobian of the residual at x. This function is only available if nls_meta(nls).jac_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure!-Union{Tuple{T}, Tuple{AbstractNLPModel, AbstractVector{T}, AbstractVector{T}}} where T","page":"Reference","title":"NLPModels.jac_structure!","text":"jac_structure!(nlp, rows, cols)\n\nReturn the structure of the constraints Jacobian in sparse coordinate format in place. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.jac_structure","text":"(rows,cols) = jac_structure(nlp)\n\nReturn the structure of the constraints Jacobian in sparse coordinate format. This function is only available when both nlp.meta.jac_available and nlp.meta.sparse_jacobian are set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jac_structure_residual!","page":"Reference","title":"NLPModels.jac_structure_residual!","text":"(rows,cols) = jac_structure_residual!(nls, rows, cols)\n\nReturns the structure of the constraint's Jacobian in sparse coordinate format in place. This function is only available if nls_meta(nls).jac_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jac_structure_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.jac_structure_residual","text":"(rows,cols) = jac_structure_residual(nls)\n\nReturns the structure of the constraint's Jacobian in sparse coordinate format. This function is only available if nls_meta(nls).jac_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod!","text":"Jv = jprod!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the Jacobian-vector product at x in place. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod!","text":"Jv = jprod!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jprod","text":"Jv = jprod(nlp, x, v)\n\nEvaluate J(x)v, the Jacobian-vector product at x. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_lin!","page":"Reference","title":"NLPModels.jprod_lin!","text":"Jv = jprod_lin!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the linear Jacobian-vector product at x in place. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_lin!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_lin!","text":"Jv = jprod_lin!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the linear Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_lin-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jprod_lin","text":"Jv = jprod_lin(nlp, x, v)\n\nEvaluate J(x)v, the linear Jacobian-vector product at x. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_nln!","page":"Reference","title":"NLPModels.jprod_nln!","text":"Jv = jprod_nln!(nlp, x, v, Jv)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product at x in place. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_nln!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_nln!","text":"Jv = jprod_nln!(nlp, rows, cols, vals, v, Jv)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_nln-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jprod_nln","text":"Jv = jprod_nln(nlp, x, v)\n\nEvaluate J(x)v, the nonlinear Jacobian-vector product at x. This function is only available if nlp.meta.jprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_residual!","page":"Reference","title":"NLPModels.jprod_residual!","text":"Jv = jprod_residual!(nls, x, v, Jv)\n\nComputes the product of the Jacobian of the residual at x and a vector, i.e., J(x)v, storing it in Jv. This function is only available if nls_meta(nls).jprod_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jprod_residual!-Tuple{AbstractNLSModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jprod_residual!","text":"Jv = jprod_residual!(nls, rows, cols, vals, v, Jv)\n\nComputes the product of the Jacobian of the residual given by (rows, cols, vals) and a vector, i.e., J(x)v, storing it in Jv. This function is only available if nls_meta(nls).jprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jprod_residual","text":"Jv = jprod_residual(nls, x, v)\n\nComputes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)v. This function is only available if nls_meta(nls).jprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess-Tuple{AbstractNLPModel, AbstractVector, Integer}","page":"Reference","title":"NLPModels.jth_hess","text":"Hx = jth_hess(nlp, x, j)\n\nEvaluate the Hessian of j-th constraint at x as a sparse matrix with the same sparsity pattern as the Lagrangian Hessian. A Symmetric object wrapping the lower triangle is returned. This function is only available when nlp.meta.sparse_hessian is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_coord!","page":"Reference","title":"NLPModels.jth_hess_coord!","text":"vals = jth_hess_coord!(nlp, x, j, vals)\n\nEvaluate the Hessian of j-th constraint at x, overwriting vals. Only the lower triangle is returned. It uses a sparse coordinate format, with vals of length nlp.meta.nnzh, when nlp.meta.sparse_hessian is set to true. Otherwise, vals is expected to be a dense matrix.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jth_hess_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, Integer}} where {T, S}","page":"Reference","title":"NLPModels.jth_hess_coord","text":"vals = jth_hess_coord(nlp, x, j)\n\nEvaluate the Hessian of j-th constraint at x in sparse coordinate format. Only the lower triangle is returned. This function is only available when nlp.meta.sparse_hessian is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64}} where {T, S}","page":"Reference","title":"NLPModels.jth_hess_residual","text":"Hj = jth_hess_residual(nls, x, j)\n\nComputes the Hessian of the j-th residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_residual_coord!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jth_hess_residual_coord!","text":"vals = jth_hess_residual_coord!(nls, x, j, vals)\n\nEvaluate the Hessian of j-th residual at x in sparse coordinate format, with vals of length nls.nls_meta.nnzh, in place. Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hess_residual_coord-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, Int64}} where {T, S}","page":"Reference","title":"NLPModels.jth_hess_residual_coord","text":"vals = jth_hess_residual_coord(nls, x, j)\n\nEvaluate the Hessian of j-th residual at x in sparse coordinate format. Only the lower triangle is returned.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jth_hprod!","page":"Reference","title":"NLPModels.jth_hprod!","text":"Hv = jth_hprod!(nlp, x, v, j, Hv)\n\nEvaluate the product of the Hessian of j-th constraint at x with the vector v in place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jth_hprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector, Integer}} where {T, S}","page":"Reference","title":"NLPModels.jth_hprod","text":"Hv = jth_hprod(nlp, x, v, j)\n\nEvaluate the product of the Hessian of j-th constraint at x with the vector v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod!","text":"Jtv = jtprod!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product at x in place. If the problem has linear and nonlinear constraints, this function allocates. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod!","text":"Jtv = jtprod!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jtprod","text":"Jtv = jtprod(nlp, x, v)\n\nEvaluate J(x)^Tv, the transposed-Jacobian-vector product at x. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_lin!","page":"Reference","title":"NLPModels.jtprod_lin!","text":"Jtv = jtprod_lin!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product at x in place. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_lin!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_lin!","text":"Jtv = jtprod_lin!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_lin-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jtprod_lin","text":"Jtv = jtprod_lin(nlp, x, v)\n\nEvaluate J(x)^Tv, the linear transposed-Jacobian-vector product at x. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_nln!","page":"Reference","title":"NLPModels.jtprod_nln!","text":"Jtv = jtprod_nln!(nlp, x, v, Jtv)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product at x in place. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_nln!-Tuple{AbstractNLPModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_nln!","text":"Jtv = jtprod_nln!(nlp, rows, cols, vals, v, Jtv)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product, where the Jacobian is given by (rows, cols, vals) in triplet format. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_nln-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jtprod_nln","text":"Jtv = jtprod_nln(nlp, x, v)\n\nEvaluate J(x)^Tv, the nonlinear transposed-Jacobian-vector product at x. This function is only available if nlp.meta.jtprod_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_residual!","page":"Reference","title":"NLPModels.jtprod_residual!","text":"Jtv = jtprod_residual!(nls, x, v, Jtv)\n\nComputes the product of the transpose of the Jacobian of the residual at x and a vector, i.e., J(x)^Tv, storing it in Jtv. This function is only available if nls_meta(nls).jtprod_residual_available is set to true.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.jtprod_residual!-Tuple{AbstractNLSModel, AbstractVector{<:Integer}, AbstractVector{<:Integer}, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.jtprod_residual!","text":"Jtv = jtprod_residual!(nls, rows, cols, vals, v, Jtv)\n\nComputes the product of the transpose of the Jacobian of the residual given by (rows, cols, vals) and a vector, i.e., J(x)^Tv, storing it in Jv. This function is only available if nls_meta(nls).jtprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.jtprod_residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.jtprod_residual","text":"Jtv = jtprod_residual(nls, x, v)\n\nComputes the product of the transpose of the Jacobian of the residual at x and a vector, i.e., J(x)^Tv. This function is only available if nls_meta(nls).jtprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lagscale","page":"Reference","title":"NLPModels.lagscale","text":"lagscale(model::AbstractNLPModel)\n\nReturn a vector of scaling factors for the Lagrange multipliers associated with constraints. This can be used to improve numerical stability or condition number when solving KKT systems.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.linearly_constrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.linearly_constrained","text":"linearly_constrained(nlp)\nlinearly_constrained(meta)\n\nReturns whether the problem's constraints are known to be all linear.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_description-Tuple{M} where M<:AbstractNLPModelMeta","page":"Reference","title":"NLPModels.lines_of_description","text":"lines_of_description(meta)\n\nDescribe meta for the show function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_description-Tuple{NLSMeta}","page":"Reference","title":"NLPModels.lines_of_description","text":"lines_of_description(nls_meta)\n\nDescribe nls_meta for the show function.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.lines_of_hist-Tuple{Any, Any}","page":"Reference","title":"NLPModels.lines_of_hist","text":"lines_of_hist(S, V)\n\nReturn a vector of histline(s, v, maxv)s using pairs of s in S and v in V. maxv is given by the maximum of V.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons","text":"neval_cons(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons_lin","text":"neval_cons_lin(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_cons_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_cons_nln","text":"neval_cons_nln(nlp)\n\nGet the number of cons evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_grad-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_grad","text":"neval_grad(nlp)\n\nGet the number of grad evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hess-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_hess","text":"neval_hess(nlp)\n\nGet the number of hess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hess_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_hess_residual","text":"neval_hess_residual(nlp)\n\nGet the number of hess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_hprod","text":"neval_hprod(nlp)\n\nGet the number of hprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_hprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_hprod_residual","text":"neval_hprod_residual(nlp)\n\nGet the number of hprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac","text":"neval_jac(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac_lin","text":"neval_jac_lin(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jac_nln","text":"neval_jac_nln(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jac_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jac_residual","text":"neval_jac_residual(nlp)\n\nGet the number of jac evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jcon-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jcon","text":"neval_jcon(nlp)\n\nGet the number of jcon evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jgrad-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jgrad","text":"neval_jgrad(nlp)\n\nGet the number of jgrad evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhess-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jhess","text":"neval_jhess(nlp)\n\nGet the number of jhess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhess_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jhess_residual","text":"neval_jhess_residual(nlp)\n\nGet the number of jhess evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jhprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jhprod","text":"neval_jhprod(nlp)\n\nGet the number of jhprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod","text":"neval_jprod(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod_lin","text":"neval_jprod_lin(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jprod_nln","text":"neval_jprod_nln(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jprod_residual","text":"neval_jprod_residual(nlp)\n\nGet the number of jprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod","text":"neval_jtprod(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_lin-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod_lin","text":"neval_jtprod_lin(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_nln-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_jtprod_nln","text":"neval_jtprod_nln(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_jtprod_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_jtprod_residual","text":"neval_jtprod_residual(nlp)\n\nGet the number of jtprod evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_obj-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.neval_obj","text":"neval_obj(nlp)\n\nGet the number of obj evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.neval_residual-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.neval_residual","text":"neval_residual(nlp)\n\nGet the number of residual evaluations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.nls_meta-Tuple{AbstractNLSModel}","page":"Reference","title":"NLPModels.nls_meta","text":"nls_meta(nls)\n\nReturns the nls_meta structure of nls. Use this instead of nls.nls_meta to handle models that have internal models.\n\nFor basic models nls_meta(nls) is defined as nls.nls_meta, but composite models might not keep nls_meta themselves, so they might specialize it to something like nls.internal.nls_meta.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.obj-Tuple{AbstractNLSModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nls, x)\nf = obj(nls, x, Fx; recompute::Bool=true)\n\nEvaluate f(x), the objective function of nls::AbstractNLSModel. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objcons!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.objcons!","text":"f, c = objcons!(nlp, x, c)\n\nEvaluate f(x) and c(x) at x. c is overwritten with the value of c(x).\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objcons!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.objcons!","text":"f, c = objcons!(nls, x, c)\nf, c = objcons!(nls, x, c, Fx; recompute::Bool=true)\n\nIn-place evaluation of constraints and objective for AbstractNLSModel. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objcons-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.objcons","text":"f, c = objcons(nlp, x)\n\nEvaluate f(x) and c(x) at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad!-Tuple{AbstractNLPModel, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.objgrad!","text":"f, g = objgrad!(nlp, x, g)\n\nEvaluate f(x) and f(x) at x. g is overwritten with the value of f(x). This function is only available if nlp.meta.grad_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad!-Tuple{AbstractNLSModel, AbstractVector, AbstractVector, AbstractVector}","page":"Reference","title":"NLPModels.objgrad!","text":"f, g = objgrad!(nls, x, g)\nf, g = objgrad!(nls, x, g, Fx; recompute::Bool=true)\n\nEvaluate f(x) and ∇f(x) of nls::AbstractNLSModel at x. Fx is overwritten with the value of the residual F(x). If recompute is true, then Fx is updated with the residual at x. This function is only available if nls_meta(nls).jtprod_residual_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLPModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.objgrad","text":"f, g = objgrad(nlp, x)\n\nEvaluate f(x) and f(x) at x. This function is only available if nlp.meta.grad_available is set to true.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.reset_data!-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.reset_data!","text":"reset_data!(nlp)\n\nReset model data if appropriate. This method should be overloaded if a subtype of AbstractNLPModel contains data that should be reset, such as a quasi-Newton linear operator.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.residual!","page":"Reference","title":"NLPModels.residual!","text":"Fx = residual!(nls, x, Fx)\n\nComputes F(x), the residual at x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.residual-Union{Tuple{S}, Tuple{T}, Tuple{AbstractNLSModel{T, S}, AbstractVector}} where {T, S}","page":"Reference","title":"NLPModels.residual","text":"Fx = residual(nls, x)\n\nComputes F(x), the residual at x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.show_counters-Tuple{IO, Any, Any}","page":"Reference","title":"NLPModels.show_counters","text":"show_counters(io, counters, fields)\n\nShow the fields of the struct counters.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.show_header-Tuple{IO, AbstractNLPModel}","page":"Reference","title":"NLPModels.show_header","text":"show_header(io, nlp)\n\nShow a header for the specific nlp type. Should be imported and defined for every model implementing the NLPModels API.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sparsityline-Tuple{Any, Any, Any}","page":"Reference","title":"NLPModels.sparsityline","text":"sparsityline(s, v, maxv)\n\nReturn a string of the form\n\n______NAME______: ( 80.00% sparsity)   5\n\nwhere:\n\n______NAME______ is s with padding to the left and length 16.\nThe sparsity value is given by v / maxv.\nThe number 5 is v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sum_counters-Tuple{AbstractNLPModel}","page":"Reference","title":"NLPModels.sum_counters","text":"sum_counters(nlp)\n\nSum all counters of problem nlp except cons, jac, jprod and jtprod.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.sum_counters-Tuple{Counters}","page":"Reference","title":"NLPModels.sum_counters","text":"sum_counters(counters)\n\nSum all counters of counters except cons, jac, jprod and jtprod.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.unconstrained-Tuple{AbstractNLPModelMeta}","page":"Reference","title":"NLPModels.unconstrained","text":"unconstrained(nlp)\nunconstrained(meta)\n\nReturns whether the problem in unconstrained.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.varscale","page":"Reference","title":"NLPModels.varscale","text":"varscale(model::AbstractNLPModel)\n\nReturn a vector containing the scaling factors for each variable in the model. This is typically used to normalize variables for numerical stability in solvers.\n\nBy default, the scaling is model-dependent. If not overridden by the model, a vector of ones  is returned. Inspired by the AMPL scaling conventions.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NLPModels.@default_counters-Tuple{Any, Any}","page":"Reference","title":"NLPModels.@default_counters","text":"@default_counters Model inner\n\nDefine functions relating counters of Model to counters of Model.inner.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@default_nlscounters-Tuple{Any, Any}","page":"Reference","title":"NLPModels.@default_nlscounters","text":"@default_nlscounters Model inner\n\nDefine functions relating NLS counters of Model to NLS counters of Model.inner.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@lencheck-Tuple{Any, Vararg{Any}}","page":"Reference","title":"NLPModels.@lencheck","text":"@lencheck n x y z …\n\nCheck that arrays x, y, z, etc. have a prescribed length n.\n\n\n\n\n\n","category":"macro"},{"location":"reference/#NLPModels.@rangecheck-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"NLPModels.@rangecheck","text":"@rangecheck ℓ u i j k …\n\nCheck that values i, j, k, etc. are in the range [ℓ,u].\n\n\n\n\n\n","category":"macro"},{"location":"#Home","page":"Home","title":"NLPModels.jl documentation","text":"This package provides general guidelines to represent non-linear programming (NLP) problems in Julia and a standardized API to evaluate the functions and their derivatives. The main objective is to be able to rely on that API when designing optimization solvers in Julia.","category":"section"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"The general form of the optimization problem is\n\nbeginaligned\nmin quad  f(x) \n c_i(x) = c_E_i quad i in cal E \n c_L_i leq c_i(x) leq c_U_i quad i in cal I \n ell leq x leq u\nendaligned\n\nwhere fmathbbR^nrightarrowmathbbR, cmathbbR^nrightarrowmathbbR^m, cal Ecup cal I = 12dotsm, cal Ecap cal I = emptyset, and c_E_i c_L_i c_U_i ell_j u_j in mathbbRcuppminfty for i = 1dotsm and j = 1dotsn.\n\nFor computational reasons, we write\n\nbeginaligned\nmin quad  f(x) \n c_L leq c(x) leq c_U \n ell leq x leq u\nendaligned\n\ndefining c_L_i = c_U_i = c_E_i for all i in cal E. The Lagrangian of this problem is defined as\n\nL(xyz^Lz^Usigma) = sigma f(x) + c(x)^T y  + sum_i=1^n z_L_i(x_i-l_i) + sum_i=1^n z_U_i(u_i-x_i)\n\nwhere sigma is a scaling parameter included for computational reasons. Since the final two sums are linear in x, the variables z_L and z_U do not appear in the Hessian nabla^2 L(xy).\n\nOptimization problems are represented by an instance/subtype of AbstractNLPModel. Such instances are composed of\n\nan instance of NLPModelMeta, which provides information about the problem, including the number of variables, constraints, bounds on the variables, etc.\nother data specific to the provenance of the problem.","category":"section"},{"location":"#Nonlinear-Least-Squares","page":"Home","title":"Nonlinear Least Squares","text":"A special subtype of AbstractNLPModel is AbstractNLSModel, i.e., Nonlinear Least Squares models. In these problems, the function f(x) is given by tfrac12Vert F(x)Vert^2, where F is referred as the residual function. The individual value of F, as well as of its derivatives, is also available.","category":"section"},{"location":"#Tools","page":"Home","title":"Tools","text":"There are a few tools to use on NLPModels, for instance to query whether the problem is constrained or not, and to get the number of function evaluations. See Tools.","category":"section"},{"location":"#Install","page":"Home","title":"Install","text":"Install NLPModels.jl with the following command.\n\npkg> add NLPModels\n\nThis will enable the use of the API and the tools described here, and it allows the creation of a manually written model. Look into Models for more information on that subject, and on a list of packages implementing ready-to-use models.","category":"section"},{"location":"#Usage","page":"Home","title":"Usage","text":"See the Models, the Tools, or the API.","category":"section"},{"location":"#Attributes","page":"Home","title":"Attributes","text":"NLPModelMeta objects have the following attributes (with S <: AbstractVector):\n\nAttribute Type Notes\nnvar Int number of variables\nx0 S initial guess\nlvar S vector of lower bounds\nuvar S vector of upper bounds\nifix Vector{Int} indices of fixed variables\nilow Vector{Int} indices of variables with lower bound only\niupp Vector{Int} indices of variables with upper bound only\nirng Vector{Int} indices of variables with lower and upper bound (range)\nifree Vector{Int} indices of free variables\niinf Vector{Int} indices of visibly infeasible bounds\nncon Int total number of general constraints\nnlin Int number of linear constraints\nnnln Int number of nonlinear general constraints\ny0 S initial Lagrange multipliers\nlcon S vector of constraint lower bounds\nucon S vector of constraint upper bounds\nlin Vector{Int} indices of linear constraints\nnln Vector{Int} indices of nonlinear constraints\njfix Vector{Int} indices of equality constraints\njlow Vector{Int} indices of constraints of the form c(x) ≥ cl\njupp Vector{Int} indices of constraints of the form c(x) ≤ cu\njrng Vector{Int} indices of constraints of the form cl ≤ c(x) ≤ cu\njfree Vector{Int} indices of \"free\" constraints (there shouldn't be any)\njinf Vector{Int} indices of the visibly infeasible constraints\nnnzo Int number of nonzeros in the gradient\nnnzj Int number of nonzeros in the Jacobian\nlin_nnzj Int number of nonzeros in the linear constraints Jacobian\nnln_nnzj Int number of nonzeros in the nonlinear constraints Jacobian\nnnzh Int number of nonzeros in the lower triangular part of the Hessian of the Lagrangian\nminimize Bool true if optimize == minimize\nislp Bool true if the problem is a linear program\nname String problem name\nsparse_jacobian Bool true if the Jacobian of the constraints is sparse\nsparse_hessian Bool true if the Hessian of the Lagrangian is sparse\ngrad_available Bool true if the gradient of the objective is available\njac_available Bool true if the Jacobian of the constraints is available\nhess_available Bool true if the Hessian of the Lagrangian is available\njprod_available Bool true if the Jacobian-vector product J * v is available\njtprod_available Bool true if the transpose Jacobian-vector product J' * v is available\nhprod_available Bool true if the Hessian-vector product of the Lagrangian H * v is available","category":"section"},{"location":"#License","page":"Home","title":"License","text":"This content is released under the MPL2.0 License.","category":"section"},{"location":"#Bug-reports-and-discussions","page":"Home","title":"Bug reports and discussions","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.\n\nIf you want to ask a question not suited for a bug report, feel free to start a discussion here. This forum is for general discussion about this repository and the JuliaSmoothOptimizers, so questions about any of our packages are welcome.","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"","category":"section"},{"location":"internals/#Internal-functions","page":"Internals","title":"Internal functions","text":"These functions may or may not be exported. They are used internally.\n\n@default_counters\n@default_nlscounters\n@lencheck\n@rangecheck\ncoo_prod!\ncoo_sym_prod!\ndecrement!\nDimensionError\nNLPModels.histline\nincrement!\nNLPModels.lines_of_description\nNLPModels.lines_of_hist\nNLPModels.show_counters\nshow_header\nNLPModels.sparsityline","category":"section"},{"location":"tools/#tools-section","page":"Tools","title":"Tools","text":"","category":"section"},{"location":"tools/#Functions-evaluations","page":"Tools","title":"Functions evaluations","text":"After calling one the API functions to get a function value, the number of times that function was called is stored inside the NLPModel. For instance\n\nusing ADNLPModels, LinearAlgebra, NLPModels\nnlp = ADNLPModel(x -> dot(x, x), zeros(2))\nfor i = 1:100\n   obj(nlp, rand(2))\nend\nneval_obj(nlp)\n\nSome counters are available for all models, some are specific. In particular, there are additional specific counters for the nonlinear least squares models (the ones with residual below).\n\nCounter Description\nneval_obj Objective\nneval_grad Gradient\nneval_cons Constraints\nneval_cons_lin Linear constraints\nneval_cons_nln Nonlinear constraints\nneval_jcon One constraint - unused\nneval_jgrad Gradient of one constraints - unused\nneval_jac Jacobian\nneval_jac_lin Linear constraints Jacobian\nneval_jac_nln Nonlinear constraints Jacobian\nneval_jprod Product of Jacobian and vector\nneval_jprod_lin Product of linear constraints Jacobian and vector\nneval_jprod_nln Product of nonlinear constraints Jacobian and vector\nneval_jtprod Product of transposed Jacobian and vector\nneval_jtprod_lin Product of transposed linear constraints Jacobian and vector\nneval_jtprod_nln Product of transposed nonlinear constraints Jacobian and vector\nneval_hess Hessian\nneval_hprod Product of Hessian and vector\nneval_jhess Individual Lagrangian Hessian evaluations\nneval_jhprod Product of Hessian of j-th function and vector\nneval_residual Residual function of nonlinear least squares model\nneval_jac_residual Jacobian of the residual\nneval_jprod_residual Product of Jacobian of residual and vector\nneval_jtprod_residual Product of transposed Jacobian of residual and vector\nneval_hess_residual Sum of Hessians of residuals\nneval_jhess_residual Hessian of a residual component\nneval_hprod_residual Product of Hessian of a residual component and vector\n\nTo get the sum of all counters except cons, jac, jprod and jtprod called for a problem, use sum_counters.\n\nusing ADNLPModels, LinearAlgebra, NLPModels\nnlp = ADNLPModel(x -> dot(x, x), zeros(2))\nobj(nlp, rand(2))\ngrad(nlp, rand(2))\nsum_counters(nlp)","category":"section"},{"location":"tools/#Querying-problem-type","page":"Tools","title":"Querying problem type","text":"There are some utility functions for querying the problem type:\n\nhas_bounds: True when not all variables are free.\nbound_constrained: True for problems with bounded variables and no other constraints.\nequality_constrained: True when problem is constrained only by equalities.\nhas_equalities: True when problem has at least one equality constraint.\ninequality_constrained: True when problem is constrained by inequalities.\nhas_inequalities: True when problem has at least one inequality constraint that isn't a bound.\nlinearly_constrained: True when problem is constrained by equalities or inequalities known to be linear.\nunconstrained: True when problem is not constrained.","category":"section"}]
}
